{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Deep Learning - Building a Deep Neural Network from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py:962: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py:962: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/matplotlib/font_manager.py:281: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  'Matplotlib is building the font cache using fc-list. '\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "import glob\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(object):\n",
    "    \"\"\"\n",
    "    Abstraction of neural network.\n",
    "    Stores parameters, activations, cached values. \n",
    "    Provides necessary functions for training and prediction. \n",
    "    \"\"\"\n",
    "    def __init__(self, layer_dimensions, activation, optimization, drop_prob=0.0, reg_lambda=0.0):\n",
    "        \"\"\"\n",
    "        Initializes the weights and biases for each layer\n",
    "        layer_dimensions: (list) number of nodes in each layer\n",
    "        activation: choice of activation functions ~ implemented relu, leaky relu, swish\n",
    "        drop_prob: drop probability for dropout layers\n",
    "        reg_lambda: regularization parameter\n",
    "        \"\"\"\n",
    "        np.random.seed(1)\n",
    "        \n",
    "        self.parameters = {}\n",
    "        self.num_layers = len(layer_dimensions)\n",
    "        self.layer_dimensions = layer_dimensions\n",
    "        self.drop_prob = drop_prob\n",
    "        self.reg_lambda = reg_lambda\n",
    "        self.activation = activation\n",
    "        self.optimizer = optimization\n",
    "        self.train_cost = []\n",
    "        self.val_cost = []\n",
    "        self.train_accuracy = []\n",
    "        self.val_accuracy = []\n",
    "        \n",
    "        # init parameters        \n",
    "        model = {}\n",
    "        \n",
    "        for i in range(len(layer_dimensions) - 1):\n",
    "            layer_ahead = layer_dimensions[i+1]\n",
    "            layer_behind = layer_dimensions[i]\n",
    "            model['W'+str(i+1)] = np.random.randn(layer_ahead, layer_behind) * np.sqrt(2.0/(layer_ahead+layer_behind))\n",
    "            model['b'+str(i+1)] = np.zeros((layer_ahead,1))\n",
    "            \n",
    "        self.parameters = model\n",
    "\n",
    "    def affineForward(self, A, W, b):\n",
    "        \"\"\"\n",
    "        Forward pass for the affine layer.\n",
    "        A: input matrix, shape (L, S), where L is the number of hidden units in the previous layer and S is\n",
    "        the number of samples\n",
    "        W: Weight Matrix\n",
    "        b: bias\n",
    "        returns: the affine product WA + b, along with the cache required for the backward pass\n",
    "        \"\"\"\n",
    "        samples = A.shape[1]\n",
    "        features = A.shape[0]\n",
    "        \n",
    "        Z = np.dot(W,A) + b\n",
    "        return Z\n",
    "\n",
    "    def activationForward(self, A):\n",
    "        \"\"\"\n",
    "        Common interface to access all activation functions.\n",
    "        A: input to the activation function\n",
    "        returns: activation(A)\n",
    "        \"\"\" \n",
    "        if self.activation == \"relu\":\n",
    "            A = self.relu(A)\n",
    "        elif self.activation == \"lrelu\":\n",
    "            A = self.leaky_relu(A,0.1)\n",
    "        elif self.activation == \"swish\":\n",
    "            A = self.swish(A)\n",
    "        return A\n",
    "\n",
    "\n",
    "    def relu(self, X):\n",
    "        \"\"\"ReLU activation unit as proposed in the Krizhevsky et al. 2012\"\"\"\n",
    "        activation = np.maximum(0,X)\n",
    "        return activation\n",
    "    \n",
    "    def leaky_relu(self, X, alpha):\n",
    "        \"\"\"Leaky ReLU activation unit.\n",
    "           alpha: the hyperparameter that replaces 0 in the ReLU\"\"\"\n",
    "        x = X.copy()\n",
    "        out = self.relu(x) - alpha * self.relu(-x)\n",
    "        return out\n",
    "        \n",
    "    def swish(self, X):\n",
    "        \"\"\"Swish activation unit as proposed by Ramachandran et al\n",
    "           https://arxiv.org/pdf/1710.05941.pdf\"\"\"\n",
    "        \n",
    "        x = X.copy()\n",
    "        out = x * self.sigmoid(x)\n",
    "        return out\n",
    "        \n",
    "    def sigmoid(self, X):\n",
    "        \"\"\"Sigmoid activation unit\"\"\"\n",
    "        x = X.copy()\n",
    "        out = 1/(1 + np.exp(-x))\n",
    "        return out\n",
    "            \n",
    "    def softmax(self, X):\n",
    "        \"\"\"Numerically Stable Softmax activation for the last layer of the Neural Network\"\"\"\n",
    "        S = X - np.amax(X, axis=0)\n",
    "        S = np.exp(S)\n",
    "        total = np.sum(S,axis=0, keepdims=True)\n",
    "        soft_m = S/total\n",
    "        \n",
    "        return soft_m\n",
    "    \n",
    "    def dropout(self, A, prob):\n",
    "        \"\"\"\n",
    "        A: Activation\n",
    "        prob: dropout prob\n",
    "        returns: tuple (A, M) \n",
    "            WHERE\n",
    "            A is matrix after applying dropout\n",
    "            M is dropout mask, used in the backward pass\n",
    "        \"\"\"\n",
    "        M = np.random.rand(A.shape[0], A.shape[1])\n",
    "        M = (M >= prob)*1.0\n",
    "        M /= (1- prob)\n",
    "        A *= M\n",
    "        return A, M\n",
    "\n",
    "    def forwardPropagation(self, X):\n",
    "        \"\"\"\n",
    "        Runs an input X through the neural network to compute activations\n",
    "        for all layers. Returns the output computed at the last layer along\n",
    "        with the cache required for backpropagation.\n",
    "        :returns: (tuple) AL, cache\n",
    "            WHERE \n",
    "            AL is activation of last layer\n",
    "            cache is cached values for each layer that\n",
    "                     are needed in further steps\n",
    "        \"\"\"\n",
    "        cache = {} #Dictionary Data Structure used to store the relevant values that will be used in further computations\n",
    "        cache['A' + str(0)] = X\n",
    "        ls = self.num_layers\n",
    "        \n",
    "        for i in range(ls - 2):\n",
    "            W = self.parameters['W' + str(i+1)]\n",
    "            b = self.parameters['b' + str(i+1)]\n",
    "            A = cache['A' + str(i)]\n",
    "            Z = self.affineForward(A, W, b)\n",
    "            A_next = self.activationForward(Z)\n",
    "            \n",
    "            if self.drop_prob > 0:\n",
    "                A_next, M = self.dropout(A_next, self.drop_prob)\n",
    "                cache['M' + str(i+1)] = M\n",
    "            \n",
    "            cache['A'+str(i+1)] = A_next\n",
    "            cache['Z'+str(i+1)] = Z\n",
    "        \n",
    "        W = self.parameters['W'+str(ls-1)]\n",
    "        b = self.parameters['b'+str(ls-1)]\n",
    "        A_class = cache['A'+str(ls-2)]\n",
    "        \n",
    "        AL = self.affineForward(A_class, W, b) #without softmax. softmax will be applied while calculating the cost function\n",
    "        \n",
    "        return AL, cache\n",
    "    \n",
    "    def costFunction(self, AL, y):\n",
    "        \"\"\"\n",
    "        AL: Activation of last layer, shape (num_classes, S)\n",
    "        y: labels, shape (S)\n",
    "        returns cost, dAL: A scalar denoting cost and the gradient of cost\n",
    "        \"\"\"\n",
    "        # compute loss\n",
    "        AL = self.softmax(AL)\n",
    "        \n",
    "        true_labels = one_hot(y)\n",
    "\n",
    "        y_hat = AL[y, range(y.shape[0])]\n",
    "        #y_hat[y_hat == 0] = 10**-10\n",
    "        #Computing the cross entropy loss\n",
    "        cost = -np.sum(np.log(y_hat))/ AL.shape[1] \n",
    "        \n",
    "        if self.reg_lambda > 0:\n",
    "            # add regularization\n",
    "            reg_loss = 0\n",
    "            for i in range(1, self.num_layers):\n",
    "                reg_loss += (0.5 * self.reg_lambda * np.sum(self.parameters[\"W\"+str(i)] * self.parameters[\"W\"+str(i)]))\n",
    "            cost += reg_loss\n",
    "                \n",
    "            #W_1, W_2, W_3 = self.parameters['W1'], self.parameters['W2'], self.parameters['W3']\n",
    "            #reg_loss = (0.5 * self.reg_lambda * np.sum(W_1*W_1)) + (0.5 * self.reg_lambda * np.sum(W_2*W_2)) + (0.5 * self.reg_lambda * np.sum(W_3*W_3))\n",
    "            #cost = cost + reg_loss\n",
    "         \n",
    "        dAL = AL - true_labels\n",
    "        return cost, dAL\n",
    "\n",
    "    def affineBackward(self, dA_prev, cache, layer):\n",
    "        \"\"\"\n",
    "        Backward pass for the affine layer.\n",
    "        dA_prev: gradient from the next layer.\n",
    "        cache: cache returned in affineForward\n",
    "        returns dA: gradient on the input to this layer\n",
    "                dW: gradient on the weights\n",
    "                db: gradient on the bias\n",
    "        \"\"\"\n",
    "        A = cache['A'+str(layer-1)]\n",
    "        W = self.parameters['W'+str(layer)]\n",
    "        samples = dA_prev.shape[1]\n",
    "        \n",
    "        if self.drop_prob > 0:\n",
    "            dA_prev = self.dropout_backward(dA_prev, cache, layer)\n",
    "        \n",
    "        dZ = self.activationBackward(dA_prev, cache, layer, \"lrelu\")\n",
    "        dW = 1/samples * np.dot(dZ, A.T)\n",
    "        db = 1/samples * np.sum(dZ, axis = 1, keepdims = True)\n",
    "        dA = np.dot(W.T, dZ)\n",
    "        \n",
    "        return dA, dW, db\n",
    "\n",
    "    def activationBackward(self, dA, cache, layer, activation):\n",
    "        \"\"\"\n",
    "        Interface to call backward on activation functions.\n",
    "        In this case, it's just relu. \n",
    "        \"\"\"\n",
    "        Z = cache['Z'+str(layer)]\n",
    "        if activation == \"relu\":\n",
    "            dx = self.relu_derivative(dA, Z)\n",
    "        elif activation == \"lrelu\":\n",
    "            dx = self.lrelu_derivative(dA, Z, 0.1)\n",
    "        elif activation == \"swish\":\n",
    "            dx = self.swish_derivative(dA, Z)\n",
    "        return dx\n",
    "    \n",
    "    def relu_derivative(self, dx, cached_x):\n",
    "        \"\"\"Derivative of ReLU activation used during Backpropagation\"\"\"\n",
    "        dA = dx * 1 * (cached_x > 0)\n",
    "        return dA\n",
    "\n",
    "    def lrelu_derivative(self, dx, cached_x, alpha):\n",
    "        \"\"\"Derivative of Leaky ReLU activation used during Backpropagation\"\"\"\n",
    "        dA = np.ones_like(cached_x)\n",
    "        dA[cached_x < 0] = alpha\n",
    "        return dA*dx\n",
    "    \n",
    "    def swish_derivative(self, dx, cached_x, beta):\n",
    "        \"\"\"Derivative of Swish activation used during Backpropagation\"\"\"\n",
    "        sig = self.sigmoid(dx)\n",
    "        return sig + (dx*sig*(1-sig))\n",
    "    \n",
    "    def dropout_backward(self, dA, cache, layer):\n",
    "        \"\"\"Derivative of Dropout used during Backpropagation\"\"\"\n",
    "        m= cache['M' + str(layer)]\n",
    "        return np.multiply(m, dA) / (1 - self.drop_prob)\n",
    "\n",
    "    def backPropagation(self, dAL, AL, cache):\n",
    "        \"\"\"\n",
    "        Run backpropagation to compute gradients on all paramters in the model\n",
    "        dAL: gradient on the last layer of the network. Returned by the cost function.\n",
    "        Y: labels\n",
    "        cache: cached values during forwardprop\n",
    "        returns gradients: dW and db for each weight/bias\n",
    "        \"\"\"\n",
    "        gradients = {}\n",
    "        \n",
    "\n",
    "        samples = AL.shape[1]\n",
    "        features = AL.shape[0]\n",
    "        layers = self.num_layers\n",
    "        \n",
    "        #computing gradients using error at the output, bias at the output, and the weight matrix immediately before\n",
    "        A = cache['A' + str(layers - 2)] # Activations at the layer previous layer\n",
    "        W = self.parameters['W' + str(layers - 1)]\n",
    "        dZ = dAL\n",
    "        dW = 1/samples * np.dot(dZ, A.T)\n",
    "        db = 1/samples * np.sum(dZ, axis = 1, keepdims = True)\n",
    "        dA = np.dot(W.T, dZ)\n",
    "        \n",
    "        gradients['dW' + str(self.num_layers - 1)] = dW\n",
    "        gradients['db' + str(self.num_layers - 1)] = db\n",
    "        \n",
    "        \n",
    "        for layer in range(layers-2,0,-1):\n",
    "            dA, dW, db = self.affineBackward(dA, cache, layer)\n",
    "            gradients['dW' + str(layer)] = dW\n",
    "            gradients['db' + str(layer)] = db\n",
    "            \n",
    "            \n",
    "           \n",
    "        if self.reg_lambda > 0:\n",
    "            # add gradients from L2 regularization to each dW\n",
    "            for i in range(self.num_layers - 2):\n",
    "                dW = gradients['dW' + str(i + 1)]\n",
    "                W = self.parameters['W' + str(i + 1)]\n",
    "                dW_updated = dW + self.reg_lambda /samples * W\n",
    "                gradients['dW' + str(i + 1)] = dW_updated\n",
    "        \n",
    "        return gradients\n",
    "\n",
    "\n",
    "    def updateParameters(self, gradients, alpha, iteration, Optim_Dict):\n",
    "        \"\"\"\n",
    "        Updates the parameters according to the Optimization algorithm specified\n",
    "        gradients: gradients for each weight/bias\n",
    "        alpha: step size for gradient descent \n",
    "        \"\"\"\n",
    "        if self.optimizer == \"Adam\":\n",
    "            #Hyperparameters for Adam Optimization ~ beta1 and beta2 corresponds to the decay rates and eps ensure division is not by zero\n",
    "            beta1, beta2, eps = 0.9, 0.999, 1e-8\n",
    "\n",
    "            for l in range(1, self.num_layers):\n",
    "                Optim_Dict[\"Vdw\"+str(l)] = (beta1 * Optim_Dict[\"Vdw\"+str(l)]) + ((1 - beta1) * gradients[\"dW\" + str(l)])\n",
    "                Optim_Dict[\"Vdb\"+str(l)] = (beta1 * Optim_Dict[\"Vdb\"+str(l)]) + ((1 - beta1) * gradients[\"db\" + str(l)])\n",
    "                Optim_Dict[\"Sdw\"+str(l)] = (beta2 * Optim_Dict[\"Sdw\"+str(l)]) + ((1 - beta2) * (gradients[\"dW\" + str(l)] * gradients[\"dW\" + str(l)]))\n",
    "                Optim_Dict[\"Sdb\"+str(l)] = (beta2 * Optim_Dict[\"Sdb\"+str(l)]) + ((1 - beta2) * (gradients[\"db\" + str(l)] * gradients[\"db\" + str(l)]))\n",
    "\n",
    "                Vdw_corr = (Optim_Dict[\"Vdw\"+str(l)])/(1 - (beta1**(iteration+1)))\n",
    "                Vdb_corr = (Optim_Dict[\"Vdb\"+str(l)])/(1 - (beta1**(iteration+1)))\n",
    "                Sdw_corr = (Optim_Dict[\"Sdw\"+str(l)])/(1 - (beta2**(iteration+1)))\n",
    "                Sdb_corr = (Optim_Dict[\"Sdb\"+str(l)])/(1 - (beta2**(iteration+1)))\n",
    "\n",
    "                self.parameters[\"W\" + str(l)] = self.parameters[\"W\" + str(l)] - alpha * (Vdw_corr/(np.sqrt(Sdw_corr) + eps))\n",
    "                self.parameters[\"b\" + str(l)] = self.parameters[\"b\" + str(l)] - alpha * (Vdb_corr/(np.sqrt(Sdb_corr) + eps))\n",
    "\n",
    "        elif self.optimizer == \"SGD\":\n",
    "            for l in range(1, self.num_layers):\n",
    "                self.parameters[\"W\" + str(l)] = self.parameters[\"W\" + str(l)] - alpha * gradients[\"dW\" + str(l)]\n",
    "                self.parameters[\"b\" + str(l)] = self.parameters[\"b\" + str(l)] - alpha * gradients[\"db\" + str(l)]\n",
    "        \n",
    "    def train(self, X, y, iters=1000, alpha=0.001, batch_size=100, print_every=100):\n",
    "        \"\"\"\n",
    "        X: input samples, each column is a sample\n",
    "        y: labels for input samples, y.shape[0] must equal X.shape[1]\n",
    "        iters: number of training iterations\n",
    "        alpha: step size for gradient descent\n",
    "        batch_size: number of samples in a minibatch\n",
    "        print_every: no. of iterations to print debug info after\n",
    "        \"\"\"\n",
    "        validation_size = int(X.shape[1]*.1)\n",
    "        total_size = X.shape[1]\n",
    "        validation_X = X[:,total_size - validation_size:]\n",
    "        validation_y = y[total_size - validation_size:]\n",
    "        \n",
    "        X = X[:,0:total_size - validation_size]\n",
    "        y = y[0:total_size - validation_size]\n",
    "        \n",
    "        shapes = []\n",
    "        for j in range(len(self.layer_dimensions) - 1):\n",
    "            shapes.append((self.layer_dimensions[j], self.layer_dimensions[j+1]))\n",
    "        \n",
    "        #initializing momentum and ubiases for advanced optimization techniques\n",
    "        Optim_Dict = {}\n",
    "        if self.optimizer != \"SGD\":\n",
    "            for l in range(0, len(shapes)):\n",
    "                layer_ahead = shapes[l][1]\n",
    "                layer_behind = shapes[l][0]\n",
    "\n",
    "                Optim_Dict[\"Vdw\" + str(l+1)] = np.zeros((layer_ahead, layer_behind))\n",
    "                Optim_Dict[\"Vdb\" + str(l+1)] = np.zeros((layer_ahead, 1))\n",
    "                Optim_Dict[\"Sdw\" + str(l+1)] = np.zeros((layer_ahead, layer_behind))\n",
    "                Optim_Dict[\"Sdb\" + str(l+1)] = np.zeros((layer_ahead, 1))\n",
    "        \n",
    "        for i in range(0, iters):\n",
    "            # get minibatch\n",
    "            X_batch, y_batch = self.get_batch(X, y, batch_size)\n",
    "            \n",
    "            # forward prop\n",
    "            AL, cache = self.forwardPropagation(X_batch)\n",
    "            \n",
    "            # compute loss\n",
    "            cost, dAL = self.costFunction(AL, y_batch)\n",
    "\n",
    "            # compute gradients\n",
    "            gradients = self.backPropagation(dAL, AL, cache)\n",
    "\n",
    "            # update weights and biases based on gradient\n",
    "            self.updateParameters(gradients, alpha, i, Optim_Dict)\n",
    "            \n",
    "            if i % print_every == 0:\n",
    "                t_pred = np.argmax(AL, axis=0)\n",
    "                train_pred = np.mean(t_pred == y_batch)*100\n",
    "                self.train_accuracy.append(train_pred)\n",
    "                self.train_cost.append(cost)\n",
    "                print(\"Training Set Accuracy after,\",i,\"iteration = \", round(train_pred,2),\"%\") \n",
    "                print(\"Training Set Cost after,\",i,\"iteration = \",round(cost,3))\n",
    "                \n",
    "                v_pred = self.predict(validation_X)\n",
    "                val_pred = np.mean(v_pred == validation_y)*100\n",
    "                self.val_accuracy.append(val_pred)\n",
    "                print(\"Validation Set Accuracy after,\",i,\"iteration = \", round(val_pred,2), \"%\")\n",
    "                print()\n",
    "\n",
    "                \n",
    "                \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make predictions for each sample\n",
    "        \"\"\"\n",
    "        AL, _ = self.forwardPropagation(X)\n",
    "        y_pred = np.argmax(AL, axis=0)\n",
    "        \n",
    "        return y_pred\n",
    "\n",
    "    def get_batch(self, X, y, batch_size):\n",
    "        \"\"\"\n",
    "        Return minibatch of samples and labels\n",
    "        \n",
    "        X, y: samples and corresponding labels\n",
    "        batch_size: minibatch size\n",
    "        returns: (tuple) X_batch, y_batch\n",
    "        \"\"\"\n",
    "        idx = np.random.choice(X.shape[1], batch_size, replace=True)\n",
    "        X_batch = X[:,idx]\n",
    "        y_batch = y[idx]\n",
    "\n",
    "        return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "\n",
    "def get_img_array(path):\n",
    "    \"\"\"\n",
    "    Given path of image, returns it's numpy array\n",
    "    \"\"\"\n",
    "    return scipy.misc.imread(path)\n",
    "\n",
    "def get_files(folder):\n",
    "    \"\"\"\n",
    "    Given path to folder, returns list of files in it\n",
    "    \"\"\"\n",
    "    filenames = [file for file in glob.glob(folder+'*/*')]\n",
    "    filenames.sort()\n",
    "    return filenames\n",
    "\n",
    "def get_label(filepath, label2id):\n",
    "    \"\"\"\n",
    "    Files are assumed to be labeled as: /path/to/file/999_frog.png\n",
    "    Returns label for a filepath\n",
    "    \"\"\"\n",
    "    tokens = filepath.split('/')\n",
    "    label = tokens[-1].split('_')[1][:-4]\n",
    "    if label in label2id:\n",
    "        return label2id[label]\n",
    "    else:\n",
    "        sys.exit(\"Invalid label: \" + label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Functions to load data\n",
    "\n",
    "def get_labels(folder, label2id):\n",
    "    \"\"\"\n",
    "    Returns vector of labels extracted from filenames of all files in folder\n",
    "    folder: path to data folder\n",
    "    label2id: mapping of text labels to numeric ids. (Eg: automobile -> 0)\n",
    "    \"\"\"\n",
    "    files = get_files(folder)\n",
    "    y = []\n",
    "    for f in files:\n",
    "        y.append(get_label(f,label2id))\n",
    "    return np.array(y)\n",
    "\n",
    "def one_hot(y, num_classes=10):\n",
    "    \"\"\"\n",
    "    Converts each label index in y to vector with one_hot encoding\n",
    "    One-hot encoding converts categorical labels to binary values\n",
    "    \"\"\"\n",
    "    y_one_hot = np.zeros((num_classes, y.shape[0]))\n",
    "    y_one_hot[y, range(y.shape[0])] = 1\n",
    "\n",
    "    return y_one_hot\n",
    "\n",
    "def get_label_mapping(label_file):\n",
    "    \"\"\"\n",
    "    Returns mappings of label to index and index to label\n",
    "    The input file has list of labels, each on a separate line.\n",
    "    \"\"\"\n",
    "    with open(label_file, 'r') as f:\n",
    "        id2label = f.readlines()\n",
    "        id2label = [l.strip() for l in id2label]\n",
    "    label2id = {}\n",
    "    count = 0\n",
    "    for label in id2label:\n",
    "        label2id[label] = count\n",
    "        count += 1\n",
    "    return id2label, label2id\n",
    "\n",
    "def get_images(folder):\n",
    "    \"\"\"\n",
    "    returns numpy array of all samples in folder\n",
    "    each column is a sample resized to 30x30 and flattened\n",
    "    \"\"\"\n",
    "    files = get_files(folder)\n",
    "    images = []\n",
    "    count = 0\n",
    "    \n",
    "    for f in files:\n",
    "        count += 1\n",
    "        if count % 10000 == 0:\n",
    "            print(\"Loaded {}/{}\".format(count,len(files)))\n",
    "        img_arr = get_img_array(f)\n",
    "        img_arr = img_arr.flatten() / 255.0\n",
    "        images.append(img_arr)\n",
    "    X = np.column_stack(images)\n",
    "\n",
    "    return X\n",
    "\n",
    "def get_train_data(data_root_path):\n",
    "    \"\"\"\n",
    "    Return X and y\n",
    "    \"\"\"\n",
    "    train_data_path = data_root_path + 'train'\n",
    "    id2label, label2id = get_label_mapping(data_root_path+'labels.txt')\n",
    "    print(label2id)\n",
    "    X = get_images(train_data_path)\n",
    "    y = get_labels(train_data_path, label2id)\n",
    "    return X, y\n",
    "\n",
    "def save_predictions(filename, y):\n",
    "    \"\"\"\n",
    "    Dumps y into .npy file\n",
    "    \"\"\"\n",
    "    np.save(filename, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'airplane': 0, 'automobile': 1, 'bird': 2, 'cat': 3, 'deer': 4, 'dog': 5, 'frog': 6, 'horse': 7, 'ship': 8, 'truck': 9}\n",
      "Loaded 10000/50000\n",
      "Loaded 20000/50000\n",
      "Loaded 30000/50000\n",
      "Loaded 40000/50000\n",
      "Loaded 50000/50000\n",
      "Loaded 10000/10000\n",
      "Data loading done\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "data_root_path = 'cifar10/' #Specify the directory in which the data is stored\n",
    "X_train, y_train = get_train_data(data_root_path) # this may take a few minutes\n",
    "X_test = get_images(data_root_path + 'test')\n",
    "print('Data loading done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Fully-Connected Deep Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy after, 0 iteration =  9.38 %\n",
      "Training Set Cost after, 0 iteration =  2.409\n",
      "Validation Set Accuracy after, 0 iteration =  10.58 %\n",
      "\n",
      "Training Set Accuracy after, 100 iteration =  29.69 %\n",
      "Training Set Cost after, 100 iteration =  1.992\n",
      "Validation Set Accuracy after, 100 iteration =  32.44 %\n",
      "\n",
      "Training Set Accuracy after, 200 iteration =  28.91 %\n",
      "Training Set Cost after, 200 iteration =  1.902\n",
      "Validation Set Accuracy after, 200 iteration =  34.66 %\n",
      "\n",
      "Training Set Accuracy after, 300 iteration =  30.47 %\n",
      "Training Set Cost after, 300 iteration =  1.861\n",
      "Validation Set Accuracy after, 300 iteration =  31.52 %\n",
      "\n",
      "Training Set Accuracy after, 400 iteration =  30.47 %\n",
      "Training Set Cost after, 400 iteration =  1.952\n",
      "Validation Set Accuracy after, 400 iteration =  36.92 %\n",
      "\n",
      "Training Set Accuracy after, 500 iteration =  41.41 %\n",
      "Training Set Cost after, 500 iteration =  1.656\n",
      "Validation Set Accuracy after, 500 iteration =  39.36 %\n",
      "\n",
      "Training Set Accuracy after, 600 iteration =  39.84 %\n",
      "Training Set Cost after, 600 iteration =  1.591\n",
      "Validation Set Accuracy after, 600 iteration =  38.64 %\n",
      "\n",
      "Training Set Accuracy after, 700 iteration =  42.19 %\n",
      "Training Set Cost after, 700 iteration =  1.635\n",
      "Validation Set Accuracy after, 700 iteration =  38.42 %\n",
      "\n",
      "Training Set Accuracy after, 800 iteration =  39.84 %\n",
      "Training Set Cost after, 800 iteration =  1.667\n",
      "Validation Set Accuracy after, 800 iteration =  41.2 %\n",
      "\n",
      "Training Set Accuracy after, 900 iteration =  40.62 %\n",
      "Training Set Cost after, 900 iteration =  1.687\n",
      "Validation Set Accuracy after, 900 iteration =  42.7 %\n",
      "\n",
      "Training Set Accuracy after, 1000 iteration =  46.09 %\n",
      "Training Set Cost after, 1000 iteration =  1.571\n",
      "Validation Set Accuracy after, 1000 iteration =  42.58 %\n",
      "\n",
      "Training Set Accuracy after, 1100 iteration =  32.81 %\n",
      "Training Set Cost after, 1100 iteration =  1.91\n",
      "Validation Set Accuracy after, 1100 iteration =  41.36 %\n",
      "\n",
      "Training Set Accuracy after, 1200 iteration =  37.5 %\n",
      "Training Set Cost after, 1200 iteration =  1.703\n",
      "Validation Set Accuracy after, 1200 iteration =  44.24 %\n",
      "\n",
      "Training Set Accuracy after, 1300 iteration =  45.31 %\n",
      "Training Set Cost after, 1300 iteration =  1.466\n",
      "Validation Set Accuracy after, 1300 iteration =  41.34 %\n",
      "\n",
      "Training Set Accuracy after, 1400 iteration =  51.56 %\n",
      "Training Set Cost after, 1400 iteration =  1.482\n",
      "Validation Set Accuracy after, 1400 iteration =  42.44 %\n",
      "\n",
      "Training Set Accuracy after, 1500 iteration =  48.44 %\n",
      "Training Set Cost after, 1500 iteration =  1.546\n",
      "Validation Set Accuracy after, 1500 iteration =  42.98 %\n",
      "\n",
      "Training Set Accuracy after, 1600 iteration =  45.31 %\n",
      "Training Set Cost after, 1600 iteration =  1.537\n",
      "Validation Set Accuracy after, 1600 iteration =  45.88 %\n",
      "\n",
      "Training Set Accuracy after, 1700 iteration =  43.75 %\n",
      "Training Set Cost after, 1700 iteration =  1.616\n",
      "Validation Set Accuracy after, 1700 iteration =  43.06 %\n",
      "\n",
      "Training Set Accuracy after, 1800 iteration =  50.78 %\n",
      "Training Set Cost after, 1800 iteration =  1.395\n",
      "Validation Set Accuracy after, 1800 iteration =  46.72 %\n",
      "\n",
      "Training Set Accuracy after, 1900 iteration =  39.84 %\n",
      "Training Set Cost after, 1900 iteration =  1.71\n",
      "Validation Set Accuracy after, 1900 iteration =  44.96 %\n",
      "\n",
      "Training Set Accuracy after, 2000 iteration =  46.09 %\n",
      "Training Set Cost after, 2000 iteration =  1.442\n",
      "Validation Set Accuracy after, 2000 iteration =  46.18 %\n",
      "\n",
      "Training Set Accuracy after, 2100 iteration =  42.97 %\n",
      "Training Set Cost after, 2100 iteration =  1.553\n",
      "Validation Set Accuracy after, 2100 iteration =  46.08 %\n",
      "\n",
      "Training Set Accuracy after, 2200 iteration =  51.56 %\n",
      "Training Set Cost after, 2200 iteration =  1.406\n",
      "Validation Set Accuracy after, 2200 iteration =  47.64 %\n",
      "\n",
      "Training Set Accuracy after, 2300 iteration =  44.53 %\n",
      "Training Set Cost after, 2300 iteration =  1.415\n",
      "Validation Set Accuracy after, 2300 iteration =  44.6 %\n",
      "\n",
      "Training Set Accuracy after, 2400 iteration =  50.0 %\n",
      "Training Set Cost after, 2400 iteration =  1.342\n",
      "Validation Set Accuracy after, 2400 iteration =  46.24 %\n",
      "\n",
      "Training Set Accuracy after, 2500 iteration =  40.62 %\n",
      "Training Set Cost after, 2500 iteration =  1.609\n",
      "Validation Set Accuracy after, 2500 iteration =  44.7 %\n",
      "\n",
      "Training Set Accuracy after, 2600 iteration =  51.56 %\n",
      "Training Set Cost after, 2600 iteration =  1.588\n",
      "Validation Set Accuracy after, 2600 iteration =  43.9 %\n",
      "\n",
      "Training Set Accuracy after, 2700 iteration =  46.88 %\n",
      "Training Set Cost after, 2700 iteration =  1.416\n",
      "Validation Set Accuracy after, 2700 iteration =  44.6 %\n",
      "\n",
      "Training Set Accuracy after, 2800 iteration =  49.22 %\n",
      "Training Set Cost after, 2800 iteration =  1.501\n",
      "Validation Set Accuracy after, 2800 iteration =  47.0 %\n",
      "\n",
      "Training Set Accuracy after, 2900 iteration =  50.0 %\n",
      "Training Set Cost after, 2900 iteration =  1.329\n",
      "Validation Set Accuracy after, 2900 iteration =  48.1 %\n",
      "\n",
      "Training Set Accuracy after, 3000 iteration =  51.56 %\n",
      "Training Set Cost after, 3000 iteration =  1.458\n",
      "Validation Set Accuracy after, 3000 iteration =  46.02 %\n",
      "\n",
      "Training Set Accuracy after, 3100 iteration =  49.22 %\n",
      "Training Set Cost after, 3100 iteration =  1.431\n",
      "Validation Set Accuracy after, 3100 iteration =  49.08 %\n",
      "\n",
      "Training Set Accuracy after, 3200 iteration =  46.09 %\n",
      "Training Set Cost after, 3200 iteration =  1.429\n",
      "Validation Set Accuracy after, 3200 iteration =  48.4 %\n",
      "\n",
      "Training Set Accuracy after, 3300 iteration =  55.47 %\n",
      "Training Set Cost after, 3300 iteration =  1.38\n",
      "Validation Set Accuracy after, 3300 iteration =  46.44 %\n",
      "\n",
      "Training Set Accuracy after, 3400 iteration =  50.0 %\n",
      "Training Set Cost after, 3400 iteration =  1.56\n",
      "Validation Set Accuracy after, 3400 iteration =  46.54 %\n",
      "\n",
      "Training Set Accuracy after, 3500 iteration =  50.0 %\n",
      "Training Set Cost after, 3500 iteration =  1.37\n",
      "Validation Set Accuracy after, 3500 iteration =  48.94 %\n",
      "\n",
      "Training Set Accuracy after, 3600 iteration =  47.66 %\n",
      "Training Set Cost after, 3600 iteration =  1.418\n",
      "Validation Set Accuracy after, 3600 iteration =  50.28 %\n",
      "\n",
      "Training Set Accuracy after, 3700 iteration =  53.91 %\n",
      "Training Set Cost after, 3700 iteration =  1.269\n",
      "Validation Set Accuracy after, 3700 iteration =  50.24 %\n",
      "\n",
      "Training Set Accuracy after, 3800 iteration =  57.03 %\n",
      "Training Set Cost after, 3800 iteration =  1.359\n",
      "Validation Set Accuracy after, 3800 iteration =  49.84 %\n",
      "\n",
      "Training Set Accuracy after, 3900 iteration =  52.34 %\n",
      "Training Set Cost after, 3900 iteration =  1.448\n",
      "Validation Set Accuracy after, 3900 iteration =  50.24 %\n",
      "\n",
      "Training Set Accuracy after, 4000 iteration =  51.56 %\n",
      "Training Set Cost after, 4000 iteration =  1.299\n",
      "Validation Set Accuracy after, 4000 iteration =  49.26 %\n",
      "\n",
      "Training Set Accuracy after, 4100 iteration =  52.34 %\n",
      "Training Set Cost after, 4100 iteration =  1.365\n",
      "Validation Set Accuracy after, 4100 iteration =  46.04 %\n",
      "\n",
      "Training Set Accuracy after, 4200 iteration =  51.56 %\n",
      "Training Set Cost after, 4200 iteration =  1.462\n",
      "Validation Set Accuracy after, 4200 iteration =  50.34 %\n",
      "\n",
      "Training Set Accuracy after, 4300 iteration =  51.56 %\n",
      "Training Set Cost after, 4300 iteration =  1.412\n",
      "Validation Set Accuracy after, 4300 iteration =  49.1 %\n",
      "\n",
      "Training Set Accuracy after, 4400 iteration =  55.47 %\n",
      "Training Set Cost after, 4400 iteration =  1.37\n",
      "Validation Set Accuracy after, 4400 iteration =  51.08 %\n",
      "\n",
      "Training Set Accuracy after, 4500 iteration =  44.53 %\n",
      "Training Set Cost after, 4500 iteration =  1.506\n",
      "Validation Set Accuracy after, 4500 iteration =  49.6 %\n",
      "\n",
      "Training Set Accuracy after, 4600 iteration =  56.25 %\n",
      "Training Set Cost after, 4600 iteration =  1.338\n",
      "Validation Set Accuracy after, 4600 iteration =  49.66 %\n",
      "\n",
      "Training Set Accuracy after, 4700 iteration =  50.0 %\n",
      "Training Set Cost after, 4700 iteration =  1.417\n",
      "Validation Set Accuracy after, 4700 iteration =  49.02 %\n",
      "\n",
      "Training Set Accuracy after, 4800 iteration =  46.09 %\n",
      "Training Set Cost after, 4800 iteration =  1.502\n",
      "Validation Set Accuracy after, 4800 iteration =  50.24 %\n",
      "\n",
      "Training Set Accuracy after, 4900 iteration =  60.94 %\n",
      "Training Set Cost after, 4900 iteration =  1.191\n",
      "Validation Set Accuracy after, 4900 iteration =  49.02 %\n",
      "\n",
      "Training Set Accuracy after, 5000 iteration =  57.03 %\n",
      "Training Set Cost after, 5000 iteration =  1.249\n",
      "Validation Set Accuracy after, 5000 iteration =  50.06 %\n",
      "\n",
      "Training Set Accuracy after, 5100 iteration =  64.06 %\n",
      "Training Set Cost after, 5100 iteration =  1.134\n",
      "Validation Set Accuracy after, 5100 iteration =  49.52 %\n",
      "\n",
      "Training Set Accuracy after, 5200 iteration =  52.34 %\n",
      "Training Set Cost after, 5200 iteration =  1.247\n",
      "Validation Set Accuracy after, 5200 iteration =  50.7 %\n",
      "\n",
      "Training Set Accuracy after, 5300 iteration =  47.66 %\n",
      "Training Set Cost after, 5300 iteration =  1.409\n",
      "Validation Set Accuracy after, 5300 iteration =  47.06 %\n",
      "\n",
      "Training Set Accuracy after, 5400 iteration =  54.69 %\n",
      "Training Set Cost after, 5400 iteration =  1.282\n",
      "Validation Set Accuracy after, 5400 iteration =  50.56 %\n",
      "\n",
      "Training Set Accuracy after, 5500 iteration =  57.03 %\n",
      "Training Set Cost after, 5500 iteration =  1.272\n",
      "Validation Set Accuracy after, 5500 iteration =  52.0 %\n",
      "\n",
      "Training Set Accuracy after, 5600 iteration =  53.12 %\n",
      "Training Set Cost after, 5600 iteration =  1.259\n",
      "Validation Set Accuracy after, 5600 iteration =  53.58 %\n",
      "\n",
      "Training Set Accuracy after, 5700 iteration =  49.22 %\n",
      "Training Set Cost after, 5700 iteration =  1.39\n",
      "Validation Set Accuracy after, 5700 iteration =  49.82 %\n",
      "\n",
      "Training Set Accuracy after, 5800 iteration =  59.38 %\n",
      "Training Set Cost after, 5800 iteration =  1.221\n",
      "Validation Set Accuracy after, 5800 iteration =  51.82 %\n",
      "\n",
      "Training Set Accuracy after, 5900 iteration =  52.34 %\n",
      "Training Set Cost after, 5900 iteration =  1.336\n",
      "Validation Set Accuracy after, 5900 iteration =  50.86 %\n",
      "\n",
      "Training Set Accuracy after, 6000 iteration =  51.56 %\n",
      "Training Set Cost after, 6000 iteration =  1.279\n",
      "Validation Set Accuracy after, 6000 iteration =  51.56 %\n",
      "\n",
      "Training Set Accuracy after, 6100 iteration =  46.88 %\n",
      "Training Set Cost after, 6100 iteration =  1.371\n",
      "Validation Set Accuracy after, 6100 iteration =  51.16 %\n",
      "\n",
      "Training Set Accuracy after, 6200 iteration =  53.91 %\n",
      "Training Set Cost after, 6200 iteration =  1.268\n",
      "Validation Set Accuracy after, 6200 iteration =  49.3 %\n",
      "\n",
      "Training Set Accuracy after, 6300 iteration =  56.25 %\n",
      "Training Set Cost after, 6300 iteration =  1.327\n",
      "Validation Set Accuracy after, 6300 iteration =  52.32 %\n",
      "\n",
      "Training Set Accuracy after, 6400 iteration =  60.94 %\n",
      "Training Set Cost after, 6400 iteration =  1.257\n",
      "Validation Set Accuracy after, 6400 iteration =  50.9 %\n",
      "\n",
      "Training Set Accuracy after, 6500 iteration =  56.25 %\n",
      "Training Set Cost after, 6500 iteration =  1.25\n",
      "Validation Set Accuracy after, 6500 iteration =  50.6 %\n",
      "\n",
      "Training Set Accuracy after, 6600 iteration =  58.59 %\n",
      "Training Set Cost after, 6600 iteration =  1.274\n",
      "Validation Set Accuracy after, 6600 iteration =  52.48 %\n",
      "\n",
      "Training Set Accuracy after, 6700 iteration =  54.69 %\n",
      "Training Set Cost after, 6700 iteration =  1.194\n",
      "Validation Set Accuracy after, 6700 iteration =  50.7 %\n",
      "\n",
      "Training Set Accuracy after, 6800 iteration =  57.03 %\n",
      "Training Set Cost after, 6800 iteration =  1.187\n",
      "Validation Set Accuracy after, 6800 iteration =  51.6 %\n",
      "\n",
      "Training Set Accuracy after, 6900 iteration =  60.16 %\n",
      "Training Set Cost after, 6900 iteration =  1.187\n",
      "Validation Set Accuracy after, 6900 iteration =  51.74 %\n",
      "\n",
      "Training Set Accuracy after, 7000 iteration =  61.72 %\n",
      "Training Set Cost after, 7000 iteration =  1.102\n",
      "Validation Set Accuracy after, 7000 iteration =  49.6 %\n",
      "\n",
      "Training Set Accuracy after, 7100 iteration =  57.03 %\n",
      "Training Set Cost after, 7100 iteration =  1.236\n",
      "Validation Set Accuracy after, 7100 iteration =  51.9 %\n",
      "\n",
      "Training Set Accuracy after, 7200 iteration =  63.28 %\n",
      "Training Set Cost after, 7200 iteration =  1.215\n",
      "Validation Set Accuracy after, 7200 iteration =  51.38 %\n",
      "\n",
      "Training Set Accuracy after, 7300 iteration =  55.47 %\n",
      "Training Set Cost after, 7300 iteration =  1.242\n",
      "Validation Set Accuracy after, 7300 iteration =  53.7 %\n",
      "\n",
      "Training Set Accuracy after, 7400 iteration =  57.03 %\n",
      "Training Set Cost after, 7400 iteration =  1.202\n",
      "Validation Set Accuracy after, 7400 iteration =  52.04 %\n",
      "\n",
      "Training Set Accuracy after, 7500 iteration =  62.5 %\n",
      "Training Set Cost after, 7500 iteration =  1.009\n",
      "Validation Set Accuracy after, 7500 iteration =  52.34 %\n",
      "\n",
      "Training Set Accuracy after, 7600 iteration =  60.94 %\n",
      "Training Set Cost after, 7600 iteration =  1.122\n",
      "Validation Set Accuracy after, 7600 iteration =  53.5 %\n",
      "\n",
      "Training Set Accuracy after, 7700 iteration =  57.81 %\n",
      "Training Set Cost after, 7700 iteration =  1.176\n",
      "Validation Set Accuracy after, 7700 iteration =  53.16 %\n",
      "\n",
      "Training Set Accuracy after, 7800 iteration =  63.28 %\n",
      "Training Set Cost after, 7800 iteration =  1.259\n",
      "Validation Set Accuracy after, 7800 iteration =  51.26 %\n",
      "\n",
      "Training Set Accuracy after, 7900 iteration =  57.03 %\n",
      "Training Set Cost after, 7900 iteration =  1.222\n",
      "Validation Set Accuracy after, 7900 iteration =  53.72 %\n",
      "\n",
      "Training Set Accuracy after, 8000 iteration =  53.91 %\n",
      "Training Set Cost after, 8000 iteration =  1.255\n",
      "Validation Set Accuracy after, 8000 iteration =  50.04 %\n",
      "\n",
      "Training Set Accuracy after, 8100 iteration =  62.5 %\n",
      "Training Set Cost after, 8100 iteration =  1.12\n",
      "Validation Set Accuracy after, 8100 iteration =  52.16 %\n",
      "\n",
      "Training Set Accuracy after, 8200 iteration =  60.16 %\n",
      "Training Set Cost after, 8200 iteration =  1.096\n",
      "Validation Set Accuracy after, 8200 iteration =  51.8 %\n",
      "\n",
      "Training Set Accuracy after, 8300 iteration =  61.72 %\n",
      "Training Set Cost after, 8300 iteration =  1.209\n",
      "Validation Set Accuracy after, 8300 iteration =  52.04 %\n",
      "\n",
      "Training Set Accuracy after, 8400 iteration =  57.03 %\n",
      "Training Set Cost after, 8400 iteration =  1.102\n",
      "Validation Set Accuracy after, 8400 iteration =  53.52 %\n",
      "\n",
      "Training Set Accuracy after, 8500 iteration =  61.72 %\n",
      "Training Set Cost after, 8500 iteration =  1.047\n",
      "Validation Set Accuracy after, 8500 iteration =  51.58 %\n",
      "\n",
      "Training Set Accuracy after, 8600 iteration =  64.06 %\n",
      "Training Set Cost after, 8600 iteration =  1.086\n",
      "Validation Set Accuracy after, 8600 iteration =  51.68 %\n",
      "\n",
      "Training Set Accuracy after, 8700 iteration =  56.25 %\n",
      "Training Set Cost after, 8700 iteration =  1.093\n",
      "Validation Set Accuracy after, 8700 iteration =  54.16 %\n",
      "\n",
      "Training Set Accuracy after, 8800 iteration =  57.81 %\n",
      "Training Set Cost after, 8800 iteration =  1.136\n",
      "Validation Set Accuracy after, 8800 iteration =  48.52 %\n",
      "\n",
      "Training Set Accuracy after, 8900 iteration =  55.47 %\n",
      "Training Set Cost after, 8900 iteration =  1.168\n",
      "Validation Set Accuracy after, 8900 iteration =  52.42 %\n",
      "\n",
      "Training Set Accuracy after, 9000 iteration =  67.19 %\n",
      "Training Set Cost after, 9000 iteration =  1.114\n",
      "Validation Set Accuracy after, 9000 iteration =  52.2 %\n",
      "\n",
      "Training Set Accuracy after, 9100 iteration =  53.91 %\n",
      "Training Set Cost after, 9100 iteration =  1.223\n",
      "Validation Set Accuracy after, 9100 iteration =  51.32 %\n",
      "\n",
      "Training Set Accuracy after, 9200 iteration =  64.84 %\n",
      "Training Set Cost after, 9200 iteration =  1.031\n",
      "Validation Set Accuracy after, 9200 iteration =  53.2 %\n",
      "\n",
      "Training Set Accuracy after, 9300 iteration =  57.03 %\n",
      "Training Set Cost after, 9300 iteration =  1.105\n",
      "Validation Set Accuracy after, 9300 iteration =  51.74 %\n",
      "\n",
      "Training Set Accuracy after, 9400 iteration =  65.62 %\n",
      "Training Set Cost after, 9400 iteration =  1.068\n",
      "Validation Set Accuracy after, 9400 iteration =  53.46 %\n",
      "\n",
      "Training Set Accuracy after, 9500 iteration =  60.94 %\n",
      "Training Set Cost after, 9500 iteration =  1.062\n",
      "Validation Set Accuracy after, 9500 iteration =  52.5 %\n",
      "\n",
      "Training Set Accuracy after, 9600 iteration =  67.97 %\n",
      "Training Set Cost after, 9600 iteration =  0.995\n",
      "Validation Set Accuracy after, 9600 iteration =  53.02 %\n",
      "\n",
      "Training Set Accuracy after, 9700 iteration =  64.06 %\n",
      "Training Set Cost after, 9700 iteration =  1.091\n",
      "Validation Set Accuracy after, 9700 iteration =  53.46 %\n",
      "\n",
      "Training Set Accuracy after, 9800 iteration =  68.75 %\n",
      "Training Set Cost after, 9800 iteration =  1.022\n",
      "Validation Set Accuracy after, 9800 iteration =  52.8 %\n",
      "\n",
      "Training Set Accuracy after, 9900 iteration =  65.62 %\n",
      "Training Set Cost after, 9900 iteration =  0.972\n",
      "Validation Set Accuracy after, 9900 iteration =  52.28 %\n",
      "\n",
      "Training Set Accuracy after, 10000 iteration =  61.72 %\n",
      "Training Set Cost after, 10000 iteration =  1.154\n",
      "Validation Set Accuracy after, 10000 iteration =  48.92 %\n",
      "\n",
      "Training Set Accuracy after, 10100 iteration =  64.06 %\n",
      "Training Set Cost after, 10100 iteration =  1.032\n",
      "Validation Set Accuracy after, 10100 iteration =  51.12 %\n",
      "\n",
      "Training Set Accuracy after, 10200 iteration =  55.47 %\n",
      "Training Set Cost after, 10200 iteration =  1.232\n",
      "Validation Set Accuracy after, 10200 iteration =  51.16 %\n",
      "\n",
      "Training Set Accuracy after, 10300 iteration =  66.41 %\n",
      "Training Set Cost after, 10300 iteration =  1.036\n",
      "Validation Set Accuracy after, 10300 iteration =  50.9 %\n",
      "\n",
      "Training Set Accuracy after, 10400 iteration =  56.25 %\n",
      "Training Set Cost after, 10400 iteration =  1.068\n",
      "Validation Set Accuracy after, 10400 iteration =  52.84 %\n",
      "\n",
      "Training Set Accuracy after, 10500 iteration =  71.88 %\n",
      "Training Set Cost after, 10500 iteration =  0.976\n",
      "Validation Set Accuracy after, 10500 iteration =  52.28 %\n",
      "\n",
      "Training Set Accuracy after, 10600 iteration =  70.31 %\n",
      "Training Set Cost after, 10600 iteration =  0.968\n",
      "Validation Set Accuracy after, 10600 iteration =  54.8 %\n",
      "\n",
      "Training Set Accuracy after, 10700 iteration =  63.28 %\n",
      "Training Set Cost after, 10700 iteration =  1.077\n",
      "Validation Set Accuracy after, 10700 iteration =  53.48 %\n",
      "\n",
      "Training Set Accuracy after, 10800 iteration =  67.19 %\n",
      "Training Set Cost after, 10800 iteration =  0.988\n",
      "Validation Set Accuracy after, 10800 iteration =  53.02 %\n",
      "\n",
      "Training Set Accuracy after, 10900 iteration =  61.72 %\n",
      "Training Set Cost after, 10900 iteration =  1.141\n",
      "Validation Set Accuracy after, 10900 iteration =  50.3 %\n",
      "\n",
      "Training Set Accuracy after, 11000 iteration =  57.03 %\n",
      "Training Set Cost after, 11000 iteration =  1.145\n",
      "Validation Set Accuracy after, 11000 iteration =  48.78 %\n",
      "\n",
      "Training Set Accuracy after, 11100 iteration =  64.06 %\n",
      "Training Set Cost after, 11100 iteration =  1.076\n",
      "Validation Set Accuracy after, 11100 iteration =  52.6 %\n",
      "\n",
      "Training Set Accuracy after, 11200 iteration =  64.84 %\n",
      "Training Set Cost after, 11200 iteration =  1.023\n",
      "Validation Set Accuracy after, 11200 iteration =  54.64 %\n",
      "\n",
      "Training Set Accuracy after, 11300 iteration =  67.97 %\n",
      "Training Set Cost after, 11300 iteration =  0.911\n",
      "Validation Set Accuracy after, 11300 iteration =  53.12 %\n",
      "\n",
      "Training Set Accuracy after, 11400 iteration =  64.06 %\n",
      "Training Set Cost after, 11400 iteration =  0.986\n",
      "Validation Set Accuracy after, 11400 iteration =  52.34 %\n",
      "\n",
      "Training Set Accuracy after, 11500 iteration =  66.41 %\n",
      "Training Set Cost after, 11500 iteration =  1.009\n",
      "Validation Set Accuracy after, 11500 iteration =  54.16 %\n",
      "\n",
      "Training Set Accuracy after, 11600 iteration =  67.97 %\n",
      "Training Set Cost after, 11600 iteration =  0.928\n",
      "Validation Set Accuracy after, 11600 iteration =  53.28 %\n",
      "\n",
      "Training Set Accuracy after, 11700 iteration =  53.12 %\n",
      "Training Set Cost after, 11700 iteration =  1.211\n",
      "Validation Set Accuracy after, 11700 iteration =  48.94 %\n",
      "\n",
      "Training Set Accuracy after, 11800 iteration =  64.84 %\n",
      "Training Set Cost after, 11800 iteration =  1.092\n",
      "Validation Set Accuracy after, 11800 iteration =  54.68 %\n",
      "\n",
      "Training Set Accuracy after, 11900 iteration =  68.75 %\n",
      "Training Set Cost after, 11900 iteration =  0.981\n",
      "Validation Set Accuracy after, 11900 iteration =  52.14 %\n",
      "\n",
      "Training Set Accuracy after, 12000 iteration =  69.53 %\n",
      "Training Set Cost after, 12000 iteration =  1.013\n",
      "Validation Set Accuracy after, 12000 iteration =  53.3 %\n",
      "\n",
      "Training Set Accuracy after, 12100 iteration =  61.72 %\n",
      "Training Set Cost after, 12100 iteration =  1.101\n",
      "Validation Set Accuracy after, 12100 iteration =  53.0 %\n",
      "\n",
      "Training Set Accuracy after, 12200 iteration =  74.22 %\n",
      "Training Set Cost after, 12200 iteration =  0.875\n",
      "Validation Set Accuracy after, 12200 iteration =  52.18 %\n",
      "\n",
      "Training Set Accuracy after, 12300 iteration =  64.84 %\n",
      "Training Set Cost after, 12300 iteration =  1.006\n",
      "Validation Set Accuracy after, 12300 iteration =  54.2 %\n",
      "\n",
      "Training Set Accuracy after, 12400 iteration =  64.84 %\n",
      "Training Set Cost after, 12400 iteration =  0.961\n",
      "Validation Set Accuracy after, 12400 iteration =  53.54 %\n",
      "\n",
      "Training Set Accuracy after, 12500 iteration =  59.38 %\n",
      "Training Set Cost after, 12500 iteration =  1.139\n",
      "Validation Set Accuracy after, 12500 iteration =  52.36 %\n",
      "\n",
      "Training Set Accuracy after, 12600 iteration =  64.84 %\n",
      "Training Set Cost after, 12600 iteration =  0.961\n",
      "Validation Set Accuracy after, 12600 iteration =  53.7 %\n",
      "\n",
      "Training Set Accuracy after, 12700 iteration =  61.72 %\n",
      "Training Set Cost after, 12700 iteration =  1.08\n",
      "Validation Set Accuracy after, 12700 iteration =  54.14 %\n",
      "\n",
      "Training Set Accuracy after, 12800 iteration =  63.28 %\n",
      "Training Set Cost after, 12800 iteration =  1.052\n",
      "Validation Set Accuracy after, 12800 iteration =  51.54 %\n",
      "\n",
      "Training Set Accuracy after, 12900 iteration =  70.31 %\n",
      "Training Set Cost after, 12900 iteration =  0.963\n",
      "Validation Set Accuracy after, 12900 iteration =  52.5 %\n",
      "\n",
      "Training Set Accuracy after, 13000 iteration =  73.44 %\n",
      "Training Set Cost after, 13000 iteration =  0.845\n",
      "Validation Set Accuracy after, 13000 iteration =  53.98 %\n",
      "\n",
      "Training Set Accuracy after, 13100 iteration =  69.53 %\n",
      "Training Set Cost after, 13100 iteration =  0.884\n",
      "Validation Set Accuracy after, 13100 iteration =  54.82 %\n",
      "\n",
      "Training Set Accuracy after, 13200 iteration =  75.0 %\n",
      "Training Set Cost after, 13200 iteration =  0.795\n",
      "Validation Set Accuracy after, 13200 iteration =  54.0 %\n",
      "\n",
      "Training Set Accuracy after, 13300 iteration =  58.59 %\n",
      "Training Set Cost after, 13300 iteration =  1.055\n",
      "Validation Set Accuracy after, 13300 iteration =  51.48 %\n",
      "\n",
      "Training Set Accuracy after, 13400 iteration =  73.44 %\n",
      "Training Set Cost after, 13400 iteration =  0.832\n",
      "Validation Set Accuracy after, 13400 iteration =  53.3 %\n",
      "\n",
      "Training Set Accuracy after, 13500 iteration =  68.75 %\n",
      "Training Set Cost after, 13500 iteration =  0.891\n",
      "Validation Set Accuracy after, 13500 iteration =  53.14 %\n",
      "\n",
      "Training Set Accuracy after, 13600 iteration =  63.28 %\n",
      "Training Set Cost after, 13600 iteration =  1.003\n",
      "Validation Set Accuracy after, 13600 iteration =  52.0 %\n",
      "\n",
      "Training Set Accuracy after, 13700 iteration =  69.53 %\n",
      "Training Set Cost after, 13700 iteration =  0.868\n",
      "Validation Set Accuracy after, 13700 iteration =  55.38 %\n",
      "\n",
      "Training Set Accuracy after, 13800 iteration =  67.19 %\n",
      "Training Set Cost after, 13800 iteration =  0.841\n",
      "Validation Set Accuracy after, 13800 iteration =  53.78 %\n",
      "\n",
      "Training Set Accuracy after, 13900 iteration =  54.69 %\n",
      "Training Set Cost after, 13900 iteration =  1.228\n",
      "Validation Set Accuracy after, 13900 iteration =  51.88 %\n",
      "\n",
      "Training Set Accuracy after, 14000 iteration =  68.75 %\n",
      "Training Set Cost after, 14000 iteration =  0.957\n",
      "Validation Set Accuracy after, 14000 iteration =  54.22 %\n",
      "\n",
      "Training Set Accuracy after, 14100 iteration =  65.62 %\n",
      "Training Set Cost after, 14100 iteration =  0.973\n",
      "Validation Set Accuracy after, 14100 iteration =  54.7 %\n",
      "\n",
      "Training Set Accuracy after, 14200 iteration =  69.53 %\n",
      "Training Set Cost after, 14200 iteration =  0.83\n",
      "Validation Set Accuracy after, 14200 iteration =  52.28 %\n",
      "\n",
      "Training Set Accuracy after, 14300 iteration =  72.66 %\n",
      "Training Set Cost after, 14300 iteration =  0.881\n",
      "Validation Set Accuracy after, 14300 iteration =  54.3 %\n",
      "\n",
      "Training Set Accuracy after, 14400 iteration =  70.31 %\n",
      "Training Set Cost after, 14400 iteration =  0.93\n",
      "Validation Set Accuracy after, 14400 iteration =  53.2 %\n",
      "\n",
      "Training Set Accuracy after, 14500 iteration =  71.88 %\n",
      "Training Set Cost after, 14500 iteration =  0.854\n",
      "Validation Set Accuracy after, 14500 iteration =  55.64 %\n",
      "\n",
      "Training Set Accuracy after, 14600 iteration =  68.75 %\n",
      "Training Set Cost after, 14600 iteration =  0.886\n",
      "Validation Set Accuracy after, 14600 iteration =  52.14 %\n",
      "\n",
      "Training Set Accuracy after, 14700 iteration =  64.06 %\n",
      "Training Set Cost after, 14700 iteration =  1.008\n",
      "Validation Set Accuracy after, 14700 iteration =  51.36 %\n",
      "\n",
      "Training Set Accuracy after, 14800 iteration =  64.84 %\n",
      "Training Set Cost after, 14800 iteration =  0.949\n",
      "Validation Set Accuracy after, 14800 iteration =  52.28 %\n",
      "\n",
      "Training Set Accuracy after, 14900 iteration =  70.31 %\n",
      "Training Set Cost after, 14900 iteration =  0.8\n",
      "Validation Set Accuracy after, 14900 iteration =  54.38 %\n",
      "\n",
      "Training Set Accuracy after, 15000 iteration =  71.88 %\n",
      "Training Set Cost after, 15000 iteration =  0.835\n",
      "Validation Set Accuracy after, 15000 iteration =  55.12 %\n",
      "\n",
      "Training Set Accuracy after, 15100 iteration =  69.53 %\n",
      "Training Set Cost after, 15100 iteration =  0.875\n",
      "Validation Set Accuracy after, 15100 iteration =  53.66 %\n",
      "\n",
      "Training Set Accuracy after, 15200 iteration =  73.44 %\n",
      "Training Set Cost after, 15200 iteration =  0.878\n",
      "Validation Set Accuracy after, 15200 iteration =  55.1 %\n",
      "\n",
      "Training Set Accuracy after, 15300 iteration =  68.75 %\n",
      "Training Set Cost after, 15300 iteration =  1.008\n",
      "Validation Set Accuracy after, 15300 iteration =  53.7 %\n",
      "\n",
      "Training Set Accuracy after, 15400 iteration =  74.22 %\n",
      "Training Set Cost after, 15400 iteration =  0.745\n",
      "Validation Set Accuracy after, 15400 iteration =  53.94 %\n",
      "\n",
      "Training Set Accuracy after, 15500 iteration =  60.16 %\n",
      "Training Set Cost after, 15500 iteration =  1.086\n",
      "Validation Set Accuracy after, 15500 iteration =  52.3 %\n",
      "\n",
      "Training Set Accuracy after, 15600 iteration =  64.84 %\n",
      "Training Set Cost after, 15600 iteration =  0.961\n",
      "Validation Set Accuracy after, 15600 iteration =  51.56 %\n",
      "\n",
      "Training Set Accuracy after, 15700 iteration =  70.31 %\n",
      "Training Set Cost after, 15700 iteration =  0.92\n",
      "Validation Set Accuracy after, 15700 iteration =  51.78 %\n",
      "\n",
      "Training Set Accuracy after, 15800 iteration =  71.88 %\n",
      "Training Set Cost after, 15800 iteration =  0.852\n",
      "Validation Set Accuracy after, 15800 iteration =  54.16 %\n",
      "\n",
      "Training Set Accuracy after, 15900 iteration =  74.22 %\n",
      "Training Set Cost after, 15900 iteration =  0.803\n",
      "Validation Set Accuracy after, 15900 iteration =  52.46 %\n",
      "\n",
      "Training Set Accuracy after, 16000 iteration =  67.97 %\n",
      "Training Set Cost after, 16000 iteration =  0.922\n",
      "Validation Set Accuracy after, 16000 iteration =  54.44 %\n",
      "\n",
      "Training Set Accuracy after, 16100 iteration =  73.44 %\n",
      "Training Set Cost after, 16100 iteration =  0.755\n",
      "Validation Set Accuracy after, 16100 iteration =  54.64 %\n",
      "\n",
      "Training Set Accuracy after, 16200 iteration =  75.0 %\n",
      "Training Set Cost after, 16200 iteration =  0.864\n",
      "Validation Set Accuracy after, 16200 iteration =  54.68 %\n",
      "\n",
      "Training Set Accuracy after, 16300 iteration =  71.09 %\n",
      "Training Set Cost after, 16300 iteration =  0.803\n",
      "Validation Set Accuracy after, 16300 iteration =  51.12 %\n",
      "\n",
      "Training Set Accuracy after, 16400 iteration =  67.97 %\n",
      "Training Set Cost after, 16400 iteration =  0.899\n",
      "Validation Set Accuracy after, 16400 iteration =  51.42 %\n",
      "\n",
      "Training Set Accuracy after, 16500 iteration =  67.97 %\n",
      "Training Set Cost after, 16500 iteration =  0.814\n",
      "Validation Set Accuracy after, 16500 iteration =  54.32 %\n",
      "\n",
      "Training Set Accuracy after, 16600 iteration =  76.56 %\n",
      "Training Set Cost after, 16600 iteration =  0.767\n",
      "Validation Set Accuracy after, 16600 iteration =  53.2 %\n",
      "\n",
      "Training Set Accuracy after, 16700 iteration =  78.12 %\n",
      "Training Set Cost after, 16700 iteration =  0.748\n",
      "Validation Set Accuracy after, 16700 iteration =  55.24 %\n",
      "\n",
      "Training Set Accuracy after, 16800 iteration =  80.47 %\n",
      "Training Set Cost after, 16800 iteration =  0.66\n",
      "Validation Set Accuracy after, 16800 iteration =  56.1 %\n",
      "\n",
      "Training Set Accuracy after, 16900 iteration =  74.22 %\n",
      "Training Set Cost after, 16900 iteration =  0.702\n",
      "Validation Set Accuracy after, 16900 iteration =  54.58 %\n",
      "\n",
      "Training Set Accuracy after, 17000 iteration =  67.97 %\n",
      "Training Set Cost after, 17000 iteration =  0.881\n",
      "Validation Set Accuracy after, 17000 iteration =  53.68 %\n",
      "\n",
      "Training Set Accuracy after, 17100 iteration =  79.69 %\n",
      "Training Set Cost after, 17100 iteration =  0.711\n",
      "Validation Set Accuracy after, 17100 iteration =  54.22 %\n",
      "\n",
      "Training Set Accuracy after, 17200 iteration =  73.44 %\n",
      "Training Set Cost after, 17200 iteration =  0.809\n",
      "Validation Set Accuracy after, 17200 iteration =  55.36 %\n",
      "\n",
      "Training Set Accuracy after, 17300 iteration =  69.53 %\n",
      "Training Set Cost after, 17300 iteration =  0.805\n",
      "Validation Set Accuracy after, 17300 iteration =  51.88 %\n",
      "\n",
      "Training Set Accuracy after, 17400 iteration =  67.97 %\n",
      "Training Set Cost after, 17400 iteration =  0.886\n",
      "Validation Set Accuracy after, 17400 iteration =  53.06 %\n",
      "\n",
      "Training Set Accuracy after, 17500 iteration =  73.44 %\n",
      "Training Set Cost after, 17500 iteration =  0.853\n",
      "Validation Set Accuracy after, 17500 iteration =  54.6 %\n",
      "\n",
      "Training Set Accuracy after, 17600 iteration =  76.56 %\n",
      "Training Set Cost after, 17600 iteration =  0.69\n",
      "Validation Set Accuracy after, 17600 iteration =  54.78 %\n",
      "\n",
      "Training Set Accuracy after, 17700 iteration =  76.56 %\n",
      "Training Set Cost after, 17700 iteration =  0.725\n",
      "Validation Set Accuracy after, 17700 iteration =  56.08 %\n",
      "\n",
      "Training Set Accuracy after, 17800 iteration =  71.09 %\n",
      "Training Set Cost after, 17800 iteration =  0.8\n",
      "Validation Set Accuracy after, 17800 iteration =  52.8 %\n",
      "\n",
      "Training Set Accuracy after, 17900 iteration =  76.56 %\n",
      "Training Set Cost after, 17900 iteration =  0.732\n",
      "Validation Set Accuracy after, 17900 iteration =  54.74 %\n",
      "\n",
      "Training Set Accuracy after, 18000 iteration =  71.88 %\n",
      "Training Set Cost after, 18000 iteration =  0.841\n",
      "Validation Set Accuracy after, 18000 iteration =  52.46 %\n",
      "\n",
      "Training Set Accuracy after, 18100 iteration =  75.0 %\n",
      "Training Set Cost after, 18100 iteration =  0.714\n",
      "Validation Set Accuracy after, 18100 iteration =  55.64 %\n",
      "\n",
      "Training Set Accuracy after, 18200 iteration =  73.44 %\n",
      "Training Set Cost after, 18200 iteration =  0.836\n",
      "Validation Set Accuracy after, 18200 iteration =  52.06 %\n",
      "\n",
      "Training Set Accuracy after, 18300 iteration =  75.0 %\n",
      "Training Set Cost after, 18300 iteration =  0.775\n",
      "Validation Set Accuracy after, 18300 iteration =  55.28 %\n",
      "\n",
      "Training Set Accuracy after, 18400 iteration =  66.41 %\n",
      "Training Set Cost after, 18400 iteration =  0.972\n",
      "Validation Set Accuracy after, 18400 iteration =  53.52 %\n",
      "\n",
      "Training Set Accuracy after, 18500 iteration =  67.97 %\n",
      "Training Set Cost after, 18500 iteration =  0.811\n",
      "Validation Set Accuracy after, 18500 iteration =  52.26 %\n",
      "\n",
      "Training Set Accuracy after, 18600 iteration =  76.56 %\n",
      "Training Set Cost after, 18600 iteration =  0.726\n",
      "Validation Set Accuracy after, 18600 iteration =  53.22 %\n",
      "\n",
      "Training Set Accuracy after, 18700 iteration =  75.0 %\n",
      "Training Set Cost after, 18700 iteration =  0.801\n",
      "Validation Set Accuracy after, 18700 iteration =  51.94 %\n",
      "\n",
      "Training Set Accuracy after, 18800 iteration =  71.09 %\n",
      "Training Set Cost after, 18800 iteration =  0.81\n",
      "Validation Set Accuracy after, 18800 iteration =  52.36 %\n",
      "\n",
      "Training Set Accuracy after, 18900 iteration =  74.22 %\n",
      "Training Set Cost after, 18900 iteration =  0.801\n",
      "Validation Set Accuracy after, 18900 iteration =  52.86 %\n",
      "\n",
      "Training Set Accuracy after, 19000 iteration =  84.38 %\n",
      "Training Set Cost after, 19000 iteration =  0.539\n",
      "Validation Set Accuracy after, 19000 iteration =  56.22 %\n",
      "\n",
      "Training Set Accuracy after, 19100 iteration =  75.78 %\n",
      "Training Set Cost after, 19100 iteration =  0.811\n",
      "Validation Set Accuracy after, 19100 iteration =  54.34 %\n",
      "\n",
      "Training Set Accuracy after, 19200 iteration =  77.34 %\n",
      "Training Set Cost after, 19200 iteration =  0.666\n",
      "Validation Set Accuracy after, 19200 iteration =  55.3 %\n",
      "\n",
      "Training Set Accuracy after, 19300 iteration =  77.34 %\n",
      "Training Set Cost after, 19300 iteration =  0.734\n",
      "Validation Set Accuracy after, 19300 iteration =  51.46 %\n",
      "\n",
      "Training Set Accuracy after, 19400 iteration =  71.09 %\n",
      "Training Set Cost after, 19400 iteration =  0.811\n",
      "Validation Set Accuracy after, 19400 iteration =  53.4 %\n",
      "\n",
      "Training Set Accuracy after, 19500 iteration =  76.56 %\n",
      "Training Set Cost after, 19500 iteration =  0.622\n",
      "Validation Set Accuracy after, 19500 iteration =  54.86 %\n",
      "\n",
      "Training Set Accuracy after, 19600 iteration =  77.34 %\n",
      "Training Set Cost after, 19600 iteration =  0.658\n",
      "Validation Set Accuracy after, 19600 iteration =  54.46 %\n",
      "\n",
      "Training Set Accuracy after, 19700 iteration =  80.47 %\n",
      "Training Set Cost after, 19700 iteration =  0.646\n",
      "Validation Set Accuracy after, 19700 iteration =  54.48 %\n",
      "\n",
      "Training Set Accuracy after, 19800 iteration =  71.88 %\n",
      "Training Set Cost after, 19800 iteration =  0.754\n",
      "Validation Set Accuracy after, 19800 iteration =  54.0 %\n",
      "\n",
      "Training Set Accuracy after, 19900 iteration =  76.56 %\n",
      "Training Set Cost after, 19900 iteration =  0.677\n",
      "Validation Set Accuracy after, 19900 iteration =  54.18 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "layer_dimensions = [X_train.shape[0], 900, 600, 10]  # including the input and output layers\n",
    "#In the function call below, specify the activation (relu, lrelu, or swish) and optimization algorithm (Adam or SGD)\n",
    "NN = NeuralNetwork(layer_dimensions, 'lrelu', 'SGD')\n",
    "#In the function call below, specify the hyperparameters\n",
    "NN.train(X_train, y_train, iters=20000, alpha=0.03, batch_size=128, print_every=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f688748a438>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f688748a2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(NN.train_accuracy,label = \"Training Accuracy\")\n",
    "plt.plot(NN.val_accuracy, label = \"Validation Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 8 0 ... 2 4 4]\n"
     ]
    }
   ],
   "source": [
    "y_predicted = NN.predict(X_test)\n",
    "print(y_predicted)\n",
    "save_predictions('ans1-uni', y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3, 8, 0, 4, 5, 2, 8, 4, 8, 1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test if your numpy file has been saved correctly\n",
    "loaded_y = np.load('ans1-uni.npy')\n",
    "print(loaded_y.shape)\n",
    "loaded_y[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Regularized Neural Network with Dropout and L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy after, 0 iteration =  9.38 %\n",
      "Training Set Cost after, 0 iteration =  55.768\n",
      "Validation Set Accuracy after, 0 iteration =  10.6 %\n",
      "\n",
      "Training Set Accuracy after, 100 iteration =  28.91 %\n",
      "Training Set Cost after, 100 iteration =  55.17\n",
      "Validation Set Accuracy after, 100 iteration =  28.94 %\n",
      "\n",
      "Training Set Accuracy after, 200 iteration =  29.69 %\n",
      "Training Set Cost after, 200 iteration =  55.027\n",
      "Validation Set Accuracy after, 200 iteration =  32.46 %\n",
      "\n",
      "Training Set Accuracy after, 300 iteration =  37.5 %\n",
      "Training Set Cost after, 300 iteration =  54.833\n",
      "Validation Set Accuracy after, 300 iteration =  34.8 %\n",
      "\n",
      "Training Set Accuracy after, 400 iteration =  35.16 %\n",
      "Training Set Cost after, 400 iteration =  54.944\n",
      "Validation Set Accuracy after, 400 iteration =  33.74 %\n",
      "\n",
      "Training Set Accuracy after, 500 iteration =  45.31 %\n",
      "Training Set Cost after, 500 iteration =  54.587\n",
      "Validation Set Accuracy after, 500 iteration =  37.38 %\n",
      "\n",
      "Training Set Accuracy after, 600 iteration =  37.5 %\n",
      "Training Set Cost after, 600 iteration =  54.625\n",
      "Validation Set Accuracy after, 600 iteration =  38.62 %\n",
      "\n",
      "Training Set Accuracy after, 700 iteration =  45.31 %\n",
      "Training Set Cost after, 700 iteration =  54.518\n",
      "Validation Set Accuracy after, 700 iteration =  39.9 %\n",
      "\n",
      "Training Set Accuracy after, 800 iteration =  54.69 %\n",
      "Training Set Cost after, 800 iteration =  54.264\n",
      "Validation Set Accuracy after, 800 iteration =  37.18 %\n",
      "\n",
      "Training Set Accuracy after, 900 iteration =  46.09 %\n",
      "Training Set Cost after, 900 iteration =  54.345\n",
      "Validation Set Accuracy after, 900 iteration =  37.8 %\n",
      "\n",
      "Training Set Accuracy after, 1000 iteration =  40.62 %\n",
      "Training Set Cost after, 1000 iteration =  54.152\n",
      "Validation Set Accuracy after, 1000 iteration =  39.7 %\n",
      "\n",
      "Training Set Accuracy after, 1100 iteration =  45.31 %\n",
      "Training Set Cost after, 1100 iteration =  54.091\n",
      "Validation Set Accuracy after, 1100 iteration =  40.96 %\n",
      "\n",
      "Training Set Accuracy after, 1200 iteration =  35.94 %\n",
      "Training Set Cost after, 1200 iteration =  54.109\n",
      "Validation Set Accuracy after, 1200 iteration =  39.74 %\n",
      "\n",
      "Training Set Accuracy after, 1300 iteration =  44.53 %\n",
      "Training Set Cost after, 1300 iteration =  53.934\n",
      "Validation Set Accuracy after, 1300 iteration =  41.0 %\n",
      "\n",
      "Training Set Accuracy after, 1400 iteration =  42.19 %\n",
      "Training Set Cost after, 1400 iteration =  53.874\n",
      "Validation Set Accuracy after, 1400 iteration =  42.88 %\n",
      "\n",
      "Training Set Accuracy after, 1500 iteration =  42.97 %\n",
      "Training Set Cost after, 1500 iteration =  53.787\n",
      "Validation Set Accuracy after, 1500 iteration =  41.7 %\n",
      "\n",
      "Training Set Accuracy after, 1600 iteration =  37.5 %\n",
      "Training Set Cost after, 1600 iteration =  53.862\n",
      "Validation Set Accuracy after, 1600 iteration =  40.42 %\n",
      "\n",
      "Training Set Accuracy after, 1700 iteration =  49.22 %\n",
      "Training Set Cost after, 1700 iteration =  53.746\n",
      "Validation Set Accuracy after, 1700 iteration =  43.18 %\n",
      "\n",
      "Training Set Accuracy after, 1800 iteration =  47.66 %\n",
      "Training Set Cost after, 1800 iteration =  53.641\n",
      "Validation Set Accuracy after, 1800 iteration =  41.22 %\n",
      "\n",
      "Training Set Accuracy after, 1900 iteration =  45.31 %\n",
      "Training Set Cost after, 1900 iteration =  53.462\n",
      "Validation Set Accuracy after, 1900 iteration =  41.26 %\n",
      "\n",
      "Training Set Accuracy after, 2000 iteration =  45.31 %\n",
      "Training Set Cost after, 2000 iteration =  53.518\n",
      "Validation Set Accuracy after, 2000 iteration =  45.72 %\n",
      "\n",
      "Training Set Accuracy after, 2100 iteration =  48.44 %\n",
      "Training Set Cost after, 2100 iteration =  53.294\n",
      "Validation Set Accuracy after, 2100 iteration =  44.62 %\n",
      "\n",
      "Training Set Accuracy after, 2200 iteration =  47.66 %\n",
      "Training Set Cost after, 2200 iteration =  53.267\n",
      "Validation Set Accuracy after, 2200 iteration =  45.42 %\n",
      "\n",
      "Training Set Accuracy after, 2300 iteration =  39.84 %\n",
      "Training Set Cost after, 2300 iteration =  53.391\n",
      "Validation Set Accuracy after, 2300 iteration =  44.22 %\n",
      "\n",
      "Training Set Accuracy after, 2400 iteration =  43.75 %\n",
      "Training Set Cost after, 2400 iteration =  53.279\n",
      "Validation Set Accuracy after, 2400 iteration =  44.74 %\n",
      "\n",
      "Training Set Accuracy after, 2500 iteration =  45.31 %\n",
      "Training Set Cost after, 2500 iteration =  53.232\n",
      "Validation Set Accuracy after, 2500 iteration =  44.66 %\n",
      "\n",
      "Training Set Accuracy after, 2600 iteration =  39.06 %\n",
      "Training Set Cost after, 2600 iteration =  53.044\n",
      "Validation Set Accuracy after, 2600 iteration =  42.54 %\n",
      "\n",
      "Training Set Accuracy after, 2700 iteration =  53.91 %\n",
      "Training Set Cost after, 2700 iteration =  52.844\n",
      "Validation Set Accuracy after, 2700 iteration =  44.58 %\n",
      "\n",
      "Training Set Accuracy after, 2800 iteration =  50.78 %\n",
      "Training Set Cost after, 2800 iteration =  52.656\n",
      "Validation Set Accuracy after, 2800 iteration =  46.46 %\n",
      "\n",
      "Training Set Accuracy after, 2900 iteration =  42.97 %\n",
      "Training Set Cost after, 2900 iteration =  52.977\n",
      "Validation Set Accuracy after, 2900 iteration =  45.44 %\n",
      "\n",
      "Training Set Accuracy after, 3000 iteration =  47.66 %\n",
      "Training Set Cost after, 3000 iteration =  52.761\n",
      "Validation Set Accuracy after, 3000 iteration =  44.8 %\n",
      "\n",
      "Training Set Accuracy after, 3100 iteration =  40.62 %\n",
      "Training Set Cost after, 3100 iteration =  52.863\n",
      "Validation Set Accuracy after, 3100 iteration =  44.78 %\n",
      "\n",
      "Training Set Accuracy after, 3200 iteration =  47.66 %\n",
      "Training Set Cost after, 3200 iteration =  52.689\n",
      "Validation Set Accuracy after, 3200 iteration =  44.28 %\n",
      "\n",
      "Training Set Accuracy after, 3300 iteration =  54.69 %\n",
      "Training Set Cost after, 3300 iteration =  52.434\n",
      "Validation Set Accuracy after, 3300 iteration =  46.34 %\n",
      "\n",
      "Training Set Accuracy after, 3400 iteration =  53.12 %\n",
      "Training Set Cost after, 3400 iteration =  52.337\n",
      "Validation Set Accuracy after, 3400 iteration =  45.86 %\n",
      "\n",
      "Training Set Accuracy after, 3500 iteration =  56.25 %\n",
      "Training Set Cost after, 3500 iteration =  52.3\n",
      "Validation Set Accuracy after, 3500 iteration =  45.68 %\n",
      "\n",
      "Training Set Accuracy after, 3600 iteration =  51.56 %\n",
      "Training Set Cost after, 3600 iteration =  52.175\n",
      "Validation Set Accuracy after, 3600 iteration =  46.56 %\n",
      "\n",
      "Training Set Accuracy after, 3700 iteration =  56.25 %\n",
      "Training Set Cost after, 3700 iteration =  52.173\n",
      "Validation Set Accuracy after, 3700 iteration =  42.22 %\n",
      "\n",
      "Training Set Accuracy after, 3800 iteration =  57.03 %\n",
      "Training Set Cost after, 3800 iteration =  52.165\n",
      "Validation Set Accuracy after, 3800 iteration =  46.64 %\n",
      "\n",
      "Training Set Accuracy after, 3900 iteration =  54.69 %\n",
      "Training Set Cost after, 3900 iteration =  52.141\n",
      "Validation Set Accuracy after, 3900 iteration =  45.96 %\n",
      "\n",
      "Training Set Accuracy after, 4000 iteration =  41.41 %\n",
      "Training Set Cost after, 4000 iteration =  52.194\n",
      "Validation Set Accuracy after, 4000 iteration =  47.16 %\n",
      "\n",
      "Training Set Accuracy after, 4100 iteration =  46.88 %\n",
      "Training Set Cost after, 4100 iteration =  52.008\n",
      "Validation Set Accuracy after, 4100 iteration =  45.74 %\n",
      "\n",
      "Training Set Accuracy after, 4200 iteration =  49.22 %\n",
      "Training Set Cost after, 4200 iteration =  52.0\n",
      "Validation Set Accuracy after, 4200 iteration =  46.66 %\n",
      "\n",
      "Training Set Accuracy after, 4300 iteration =  54.69 %\n",
      "Training Set Cost after, 4300 iteration =  51.743\n",
      "Validation Set Accuracy after, 4300 iteration =  47.66 %\n",
      "\n",
      "Training Set Accuracy after, 4400 iteration =  49.22 %\n",
      "Training Set Cost after, 4400 iteration =  51.819\n",
      "Validation Set Accuracy after, 4400 iteration =  46.16 %\n",
      "\n",
      "Training Set Accuracy after, 4500 iteration =  48.44 %\n",
      "Training Set Cost after, 4500 iteration =  51.764\n",
      "Validation Set Accuracy after, 4500 iteration =  48.24 %\n",
      "\n",
      "Training Set Accuracy after, 4600 iteration =  50.0 %\n",
      "Training Set Cost after, 4600 iteration =  51.934\n",
      "Validation Set Accuracy after, 4600 iteration =  44.5 %\n",
      "\n",
      "Training Set Accuracy after, 4700 iteration =  52.34 %\n",
      "Training Set Cost after, 4700 iteration =  51.602\n",
      "Validation Set Accuracy after, 4700 iteration =  47.16 %\n",
      "\n",
      "Training Set Accuracy after, 4800 iteration =  53.91 %\n",
      "Training Set Cost after, 4800 iteration =  51.593\n",
      "Validation Set Accuracy after, 4800 iteration =  47.66 %\n",
      "\n",
      "Training Set Accuracy after, 4900 iteration =  52.34 %\n",
      "Training Set Cost after, 4900 iteration =  51.514\n",
      "Validation Set Accuracy after, 4900 iteration =  48.04 %\n",
      "\n",
      "Training Set Accuracy after, 5000 iteration =  48.44 %\n",
      "Training Set Cost after, 5000 iteration =  51.534\n",
      "Validation Set Accuracy after, 5000 iteration =  47.86 %\n",
      "\n",
      "Training Set Accuracy after, 5100 iteration =  47.66 %\n",
      "Training Set Cost after, 5100 iteration =  51.519\n",
      "Validation Set Accuracy after, 5100 iteration =  47.88 %\n",
      "\n",
      "Training Set Accuracy after, 5200 iteration =  53.12 %\n",
      "Training Set Cost after, 5200 iteration =  51.298\n",
      "Validation Set Accuracy after, 5200 iteration =  49.08 %\n",
      "\n",
      "Training Set Accuracy after, 5300 iteration =  51.56 %\n",
      "Training Set Cost after, 5300 iteration =  51.266\n",
      "Validation Set Accuracy after, 5300 iteration =  48.96 %\n",
      "\n",
      "Training Set Accuracy after, 5400 iteration =  49.22 %\n",
      "Training Set Cost after, 5400 iteration =  51.263\n",
      "Validation Set Accuracy after, 5400 iteration =  49.94 %\n",
      "\n",
      "Training Set Accuracy after, 5500 iteration =  46.88 %\n",
      "Training Set Cost after, 5500 iteration =  51.183\n",
      "Validation Set Accuracy after, 5500 iteration =  47.28 %\n",
      "\n",
      "Training Set Accuracy after, 5600 iteration =  42.19 %\n",
      "Training Set Cost after, 5600 iteration =  51.289\n",
      "Validation Set Accuracy after, 5600 iteration =  49.6 %\n",
      "\n",
      "Training Set Accuracy after, 5700 iteration =  50.78 %\n",
      "Training Set Cost after, 5700 iteration =  51.073\n",
      "Validation Set Accuracy after, 5700 iteration =  49.04 %\n",
      "\n",
      "Training Set Accuracy after, 5800 iteration =  51.56 %\n",
      "Training Set Cost after, 5800 iteration =  50.967\n",
      "Validation Set Accuracy after, 5800 iteration =  47.78 %\n",
      "\n",
      "Training Set Accuracy after, 5900 iteration =  53.91 %\n",
      "Training Set Cost after, 5900 iteration =  50.985\n",
      "Validation Set Accuracy after, 5900 iteration =  48.74 %\n",
      "\n",
      "Training Set Accuracy after, 6000 iteration =  60.94 %\n",
      "Training Set Cost after, 6000 iteration =  50.776\n",
      "Validation Set Accuracy after, 6000 iteration =  48.0 %\n",
      "\n",
      "Training Set Accuracy after, 6100 iteration =  53.12 %\n",
      "Training Set Cost after, 6100 iteration =  50.865\n",
      "Validation Set Accuracy after, 6100 iteration =  49.9 %\n",
      "\n",
      "Training Set Accuracy after, 6200 iteration =  57.81 %\n",
      "Training Set Cost after, 6200 iteration =  50.783\n",
      "Validation Set Accuracy after, 6200 iteration =  49.04 %\n",
      "\n",
      "Training Set Accuracy after, 6300 iteration =  57.03 %\n",
      "Training Set Cost after, 6300 iteration =  50.79\n",
      "Validation Set Accuracy after, 6300 iteration =  46.72 %\n",
      "\n",
      "Training Set Accuracy after, 6400 iteration =  55.47 %\n",
      "Training Set Cost after, 6400 iteration =  50.601\n",
      "Validation Set Accuracy after, 6400 iteration =  50.08 %\n",
      "\n",
      "Training Set Accuracy after, 6500 iteration =  51.56 %\n",
      "Training Set Cost after, 6500 iteration =  50.659\n",
      "Validation Set Accuracy after, 6500 iteration =  47.46 %\n",
      "\n",
      "Training Set Accuracy after, 6600 iteration =  53.12 %\n",
      "Training Set Cost after, 6600 iteration =  50.692\n",
      "Validation Set Accuracy after, 6600 iteration =  49.08 %\n",
      "\n",
      "Training Set Accuracy after, 6700 iteration =  51.56 %\n",
      "Training Set Cost after, 6700 iteration =  50.517\n",
      "Validation Set Accuracy after, 6700 iteration =  48.02 %\n",
      "\n",
      "Training Set Accuracy after, 6800 iteration =  50.0 %\n",
      "Training Set Cost after, 6800 iteration =  50.521\n",
      "Validation Set Accuracy after, 6800 iteration =  48.76 %\n",
      "\n",
      "Training Set Accuracy after, 6900 iteration =  53.91 %\n",
      "Training Set Cost after, 6900 iteration =  50.43\n",
      "Validation Set Accuracy after, 6900 iteration =  51.2 %\n",
      "\n",
      "Training Set Accuracy after, 7000 iteration =  42.97 %\n",
      "Training Set Cost after, 7000 iteration =  50.629\n",
      "Validation Set Accuracy after, 7000 iteration =  45.62 %\n",
      "\n",
      "Training Set Accuracy after, 7100 iteration =  50.78 %\n",
      "Training Set Cost after, 7100 iteration =  50.426\n",
      "Validation Set Accuracy after, 7100 iteration =  50.32 %\n",
      "\n",
      "Training Set Accuracy after, 7200 iteration =  53.12 %\n",
      "Training Set Cost after, 7200 iteration =  50.245\n",
      "Validation Set Accuracy after, 7200 iteration =  49.16 %\n",
      "\n",
      "Training Set Accuracy after, 7300 iteration =  53.91 %\n",
      "Training Set Cost after, 7300 iteration =  50.191\n",
      "Validation Set Accuracy after, 7300 iteration =  50.98 %\n",
      "\n",
      "Training Set Accuracy after, 7400 iteration =  55.47 %\n",
      "Training Set Cost after, 7400 iteration =  50.195\n",
      "Validation Set Accuracy after, 7400 iteration =  49.96 %\n",
      "\n",
      "Training Set Accuracy after, 7500 iteration =  53.91 %\n",
      "Training Set Cost after, 7500 iteration =  50.076\n",
      "Validation Set Accuracy after, 7500 iteration =  49.32 %\n",
      "\n",
      "Training Set Accuracy after, 7600 iteration =  59.38 %\n",
      "Training Set Cost after, 7600 iteration =  50.069\n",
      "Validation Set Accuracy after, 7600 iteration =  50.0 %\n",
      "\n",
      "Training Set Accuracy after, 7700 iteration =  57.03 %\n",
      "Training Set Cost after, 7700 iteration =  50.097\n",
      "Validation Set Accuracy after, 7700 iteration =  50.56 %\n",
      "\n",
      "Training Set Accuracy after, 7800 iteration =  51.56 %\n",
      "Training Set Cost after, 7800 iteration =  50.19\n",
      "Validation Set Accuracy after, 7800 iteration =  51.14 %\n",
      "\n",
      "Training Set Accuracy after, 7900 iteration =  47.66 %\n",
      "Training Set Cost after, 7900 iteration =  50.086\n",
      "Validation Set Accuracy after, 7900 iteration =  49.06 %\n",
      "\n",
      "Training Set Accuracy after, 8000 iteration =  48.44 %\n",
      "Training Set Cost after, 8000 iteration =  49.912\n",
      "Validation Set Accuracy after, 8000 iteration =  50.48 %\n",
      "\n",
      "Training Set Accuracy after, 8100 iteration =  58.59 %\n",
      "Training Set Cost after, 8100 iteration =  49.908\n",
      "Validation Set Accuracy after, 8100 iteration =  51.32 %\n",
      "\n",
      "Training Set Accuracy after, 8200 iteration =  57.03 %\n",
      "Training Set Cost after, 8200 iteration =  49.771\n",
      "Validation Set Accuracy after, 8200 iteration =  48.12 %\n",
      "\n",
      "Training Set Accuracy after, 8300 iteration =  57.03 %\n",
      "Training Set Cost after, 8300 iteration =  49.821\n",
      "Validation Set Accuracy after, 8300 iteration =  51.26 %\n",
      "\n",
      "Training Set Accuracy after, 8400 iteration =  57.03 %\n",
      "Training Set Cost after, 8400 iteration =  49.696\n",
      "Validation Set Accuracy after, 8400 iteration =  50.26 %\n",
      "\n",
      "Training Set Accuracy after, 8500 iteration =  52.34 %\n",
      "Training Set Cost after, 8500 iteration =  49.923\n",
      "Validation Set Accuracy after, 8500 iteration =  48.38 %\n",
      "\n",
      "Training Set Accuracy after, 8600 iteration =  57.03 %\n",
      "Training Set Cost after, 8600 iteration =  49.725\n",
      "Validation Set Accuracy after, 8600 iteration =  47.86 %\n",
      "\n",
      "Training Set Accuracy after, 8700 iteration =  57.03 %\n",
      "Training Set Cost after, 8700 iteration =  49.564\n",
      "Validation Set Accuracy after, 8700 iteration =  49.1 %\n",
      "\n",
      "Training Set Accuracy after, 8800 iteration =  47.66 %\n",
      "Training Set Cost after, 8800 iteration =  49.601\n",
      "Validation Set Accuracy after, 8800 iteration =  50.24 %\n",
      "\n",
      "Training Set Accuracy after, 8900 iteration =  49.22 %\n",
      "Training Set Cost after, 8900 iteration =  49.65\n",
      "Validation Set Accuracy after, 8900 iteration =  50.02 %\n",
      "\n",
      "Training Set Accuracy after, 9000 iteration =  59.38 %\n",
      "Training Set Cost after, 9000 iteration =  49.48\n",
      "Validation Set Accuracy after, 9000 iteration =  49.34 %\n",
      "\n",
      "Training Set Accuracy after, 9100 iteration =  57.03 %\n",
      "Training Set Cost after, 9100 iteration =  49.48\n",
      "Validation Set Accuracy after, 9100 iteration =  50.48 %\n",
      "\n",
      "Training Set Accuracy after, 9200 iteration =  47.66 %\n",
      "Training Set Cost after, 9200 iteration =  49.457\n",
      "Validation Set Accuracy after, 9200 iteration =  50.62 %\n",
      "\n",
      "Training Set Accuracy after, 9300 iteration =  48.44 %\n",
      "Training Set Cost after, 9300 iteration =  49.5\n",
      "Validation Set Accuracy after, 9300 iteration =  49.36 %\n",
      "\n",
      "Training Set Accuracy after, 9400 iteration =  47.66 %\n",
      "Training Set Cost after, 9400 iteration =  49.508\n",
      "Validation Set Accuracy after, 9400 iteration =  50.78 %\n",
      "\n",
      "Training Set Accuracy after, 9500 iteration =  55.47 %\n",
      "Training Set Cost after, 9500 iteration =  49.385\n",
      "Validation Set Accuracy after, 9500 iteration =  47.2 %\n",
      "\n",
      "Training Set Accuracy after, 9600 iteration =  64.84 %\n",
      "Training Set Cost after, 9600 iteration =  49.113\n",
      "Validation Set Accuracy after, 9600 iteration =  51.18 %\n",
      "\n",
      "Training Set Accuracy after, 9700 iteration =  55.47 %\n",
      "Training Set Cost after, 9700 iteration =  49.231\n",
      "Validation Set Accuracy after, 9700 iteration =  49.24 %\n",
      "\n",
      "Training Set Accuracy after, 9800 iteration =  60.94 %\n",
      "Training Set Cost after, 9800 iteration =  49.085\n",
      "Validation Set Accuracy after, 9800 iteration =  52.32 %\n",
      "\n",
      "Training Set Accuracy after, 9900 iteration =  53.12 %\n",
      "Training Set Cost after, 9900 iteration =  49.052\n",
      "Validation Set Accuracy after, 9900 iteration =  50.82 %\n",
      "\n",
      "Training Set Accuracy after, 10000 iteration =  53.91 %\n",
      "Training Set Cost after, 10000 iteration =  49.111\n",
      "Validation Set Accuracy after, 10000 iteration =  51.32 %\n",
      "\n",
      "Training Set Accuracy after, 10100 iteration =  57.03 %\n",
      "Training Set Cost after, 10100 iteration =  49.0\n",
      "Validation Set Accuracy after, 10100 iteration =  50.62 %\n",
      "\n",
      "Training Set Accuracy after, 10200 iteration =  60.16 %\n",
      "Training Set Cost after, 10200 iteration =  48.896\n",
      "Validation Set Accuracy after, 10200 iteration =  48.68 %\n",
      "\n",
      "Training Set Accuracy after, 10300 iteration =  55.47 %\n",
      "Training Set Cost after, 10300 iteration =  49.04\n",
      "Validation Set Accuracy after, 10300 iteration =  51.2 %\n",
      "\n",
      "Training Set Accuracy after, 10400 iteration =  51.56 %\n",
      "Training Set Cost after, 10400 iteration =  49.09\n",
      "Validation Set Accuracy after, 10400 iteration =  49.3 %\n",
      "\n",
      "Training Set Accuracy after, 10500 iteration =  51.56 %\n",
      "Training Set Cost after, 10500 iteration =  49.109\n",
      "Validation Set Accuracy after, 10500 iteration =  51.38 %\n",
      "\n",
      "Training Set Accuracy after, 10600 iteration =  53.91 %\n",
      "Training Set Cost after, 10600 iteration =  49.012\n",
      "Validation Set Accuracy after, 10600 iteration =  49.94 %\n",
      "\n",
      "Training Set Accuracy after, 10700 iteration =  60.16 %\n",
      "Training Set Cost after, 10700 iteration =  48.823\n",
      "Validation Set Accuracy after, 10700 iteration =  51.4 %\n",
      "\n",
      "Training Set Accuracy after, 10800 iteration =  67.19 %\n",
      "Training Set Cost after, 10800 iteration =  48.673\n",
      "Validation Set Accuracy after, 10800 iteration =  52.04 %\n",
      "\n",
      "Training Set Accuracy after, 10900 iteration =  55.47 %\n",
      "Training Set Cost after, 10900 iteration =  48.751\n",
      "Validation Set Accuracy after, 10900 iteration =  49.9 %\n",
      "\n",
      "Training Set Accuracy after, 11000 iteration =  61.72 %\n",
      "Training Set Cost after, 11000 iteration =  48.682\n",
      "Validation Set Accuracy after, 11000 iteration =  51.58 %\n",
      "\n",
      "Training Set Accuracy after, 11100 iteration =  61.72 %\n",
      "Training Set Cost after, 11100 iteration =  48.634\n",
      "Validation Set Accuracy after, 11100 iteration =  51.52 %\n",
      "\n",
      "Training Set Accuracy after, 11200 iteration =  58.59 %\n",
      "Training Set Cost after, 11200 iteration =  48.803\n",
      "Validation Set Accuracy after, 11200 iteration =  51.18 %\n",
      "\n",
      "Training Set Accuracy after, 11300 iteration =  59.38 %\n",
      "Training Set Cost after, 11300 iteration =  48.712\n",
      "Validation Set Accuracy after, 11300 iteration =  49.8 %\n",
      "\n",
      "Training Set Accuracy after, 11400 iteration =  54.69 %\n",
      "Training Set Cost after, 11400 iteration =  48.59\n",
      "Validation Set Accuracy after, 11400 iteration =  50.3 %\n",
      "\n",
      "Training Set Accuracy after, 11500 iteration =  60.94 %\n",
      "Training Set Cost after, 11500 iteration =  48.488\n",
      "Validation Set Accuracy after, 11500 iteration =  51.76 %\n",
      "\n",
      "Training Set Accuracy after, 11600 iteration =  60.94 %\n",
      "Training Set Cost after, 11600 iteration =  48.498\n",
      "Validation Set Accuracy after, 11600 iteration =  51.42 %\n",
      "\n",
      "Training Set Accuracy after, 11700 iteration =  55.47 %\n",
      "Training Set Cost after, 11700 iteration =  48.567\n",
      "Validation Set Accuracy after, 11700 iteration =  51.4 %\n",
      "\n",
      "Training Set Accuracy after, 11800 iteration =  59.38 %\n",
      "Training Set Cost after, 11800 iteration =  48.505\n",
      "Validation Set Accuracy after, 11800 iteration =  50.8 %\n",
      "\n",
      "Training Set Accuracy after, 11900 iteration =  60.94 %\n",
      "Training Set Cost after, 11900 iteration =  48.346\n",
      "Validation Set Accuracy after, 11900 iteration =  51.48 %\n",
      "\n",
      "Training Set Accuracy after, 12000 iteration =  60.94 %\n",
      "Training Set Cost after, 12000 iteration =  48.389\n",
      "Validation Set Accuracy after, 12000 iteration =  49.68 %\n",
      "\n",
      "Training Set Accuracy after, 12100 iteration =  62.5 %\n",
      "Training Set Cost after, 12100 iteration =  48.352\n",
      "Validation Set Accuracy after, 12100 iteration =  52.16 %\n",
      "\n",
      "Training Set Accuracy after, 12200 iteration =  61.72 %\n",
      "Training Set Cost after, 12200 iteration =  48.312\n",
      "Validation Set Accuracy after, 12200 iteration =  52.18 %\n",
      "\n",
      "Training Set Accuracy after, 12300 iteration =  64.06 %\n",
      "Training Set Cost after, 12300 iteration =  48.324\n",
      "Validation Set Accuracy after, 12300 iteration =  51.52 %\n",
      "\n",
      "Training Set Accuracy after, 12400 iteration =  56.25 %\n",
      "Training Set Cost after, 12400 iteration =  48.275\n",
      "Validation Set Accuracy after, 12400 iteration =  51.08 %\n",
      "\n",
      "Training Set Accuracy after, 12500 iteration =  61.72 %\n",
      "Training Set Cost after, 12500 iteration =  48.257\n",
      "Validation Set Accuracy after, 12500 iteration =  50.04 %\n",
      "\n",
      "Training Set Accuracy after, 12600 iteration =  52.34 %\n",
      "Training Set Cost after, 12600 iteration =  48.31\n",
      "Validation Set Accuracy after, 12600 iteration =  51.5 %\n",
      "\n",
      "Training Set Accuracy after, 12700 iteration =  51.56 %\n",
      "Training Set Cost after, 12700 iteration =  48.306\n",
      "Validation Set Accuracy after, 12700 iteration =  50.94 %\n",
      "\n",
      "Training Set Accuracy after, 12800 iteration =  45.31 %\n",
      "Training Set Cost after, 12800 iteration =  48.384\n",
      "Validation Set Accuracy after, 12800 iteration =  50.22 %\n",
      "\n",
      "Training Set Accuracy after, 12900 iteration =  65.62 %\n",
      "Training Set Cost after, 12900 iteration =  48.05\n",
      "Validation Set Accuracy after, 12900 iteration =  52.54 %\n",
      "\n",
      "Training Set Accuracy after, 13000 iteration =  60.94 %\n",
      "Training Set Cost after, 13000 iteration =  48.23\n",
      "Validation Set Accuracy after, 13000 iteration =  51.52 %\n",
      "\n",
      "Training Set Accuracy after, 13100 iteration =  64.06 %\n",
      "Training Set Cost after, 13100 iteration =  48.051\n",
      "Validation Set Accuracy after, 13100 iteration =  52.08 %\n",
      "\n",
      "Training Set Accuracy after, 13200 iteration =  60.16 %\n",
      "Training Set Cost after, 13200 iteration =  48.206\n",
      "Validation Set Accuracy after, 13200 iteration =  51.66 %\n",
      "\n",
      "Training Set Accuracy after, 13300 iteration =  57.81 %\n",
      "Training Set Cost after, 13300 iteration =  48.119\n",
      "Validation Set Accuracy after, 13300 iteration =  52.36 %\n",
      "\n",
      "Training Set Accuracy after, 13400 iteration =  62.5 %\n",
      "Training Set Cost after, 13400 iteration =  48.181\n",
      "Validation Set Accuracy after, 13400 iteration =  50.3 %\n",
      "\n",
      "Training Set Accuracy after, 13500 iteration =  58.59 %\n",
      "Training Set Cost after, 13500 iteration =  48.043\n",
      "Validation Set Accuracy after, 13500 iteration =  50.2 %\n",
      "\n",
      "Training Set Accuracy after, 13600 iteration =  58.59 %\n",
      "Training Set Cost after, 13600 iteration =  47.984\n",
      "Validation Set Accuracy after, 13600 iteration =  52.9 %\n",
      "\n",
      "Training Set Accuracy after, 13700 iteration =  63.28 %\n",
      "Training Set Cost after, 13700 iteration =  47.862\n",
      "Validation Set Accuracy after, 13700 iteration =  52.42 %\n",
      "\n",
      "Training Set Accuracy after, 13800 iteration =  62.5 %\n",
      "Training Set Cost after, 13800 iteration =  47.8\n",
      "Validation Set Accuracy after, 13800 iteration =  52.9 %\n",
      "\n",
      "Training Set Accuracy after, 13900 iteration =  67.19 %\n",
      "Training Set Cost after, 13900 iteration =  47.778\n",
      "Validation Set Accuracy after, 13900 iteration =  51.94 %\n",
      "\n",
      "Training Set Accuracy after, 14000 iteration =  62.5 %\n",
      "Training Set Cost after, 14000 iteration =  47.865\n",
      "Validation Set Accuracy after, 14000 iteration =  52.4 %\n",
      "\n",
      "Training Set Accuracy after, 14100 iteration =  64.84 %\n",
      "Training Set Cost after, 14100 iteration =  47.814\n",
      "Validation Set Accuracy after, 14100 iteration =  49.78 %\n",
      "\n",
      "Training Set Accuracy after, 14200 iteration =  64.06 %\n",
      "Training Set Cost after, 14200 iteration =  47.767\n",
      "Validation Set Accuracy after, 14200 iteration =  50.54 %\n",
      "\n",
      "Training Set Accuracy after, 14300 iteration =  67.97 %\n",
      "Training Set Cost after, 14300 iteration =  47.639\n",
      "Validation Set Accuracy after, 14300 iteration =  51.92 %\n",
      "\n",
      "Training Set Accuracy after, 14400 iteration =  59.38 %\n",
      "Training Set Cost after, 14400 iteration =  47.765\n",
      "Validation Set Accuracy after, 14400 iteration =  51.44 %\n",
      "\n",
      "Training Set Accuracy after, 14500 iteration =  61.72 %\n",
      "Training Set Cost after, 14500 iteration =  47.759\n",
      "Validation Set Accuracy after, 14500 iteration =  52.56 %\n",
      "\n",
      "Training Set Accuracy after, 14600 iteration =  66.41 %\n",
      "Training Set Cost after, 14600 iteration =  47.602\n",
      "Validation Set Accuracy after, 14600 iteration =  51.98 %\n",
      "\n",
      "Training Set Accuracy after, 14700 iteration =  63.28 %\n",
      "Training Set Cost after, 14700 iteration =  47.656\n",
      "Validation Set Accuracy after, 14700 iteration =  52.9 %\n",
      "\n",
      "Training Set Accuracy after, 14800 iteration =  57.03 %\n",
      "Training Set Cost after, 14800 iteration =  47.722\n",
      "Validation Set Accuracy after, 14800 iteration =  50.98 %\n",
      "\n",
      "Training Set Accuracy after, 14900 iteration =  65.62 %\n",
      "Training Set Cost after, 14900 iteration =  47.6\n",
      "Validation Set Accuracy after, 14900 iteration =  51.42 %\n",
      "\n",
      "Training Set Accuracy after, 15000 iteration =  55.47 %\n",
      "Training Set Cost after, 15000 iteration =  47.802\n",
      "Validation Set Accuracy after, 15000 iteration =  51.74 %\n",
      "\n",
      "Training Set Accuracy after, 15100 iteration =  61.72 %\n",
      "Training Set Cost after, 15100 iteration =  47.682\n",
      "Validation Set Accuracy after, 15100 iteration =  50.72 %\n",
      "\n",
      "Training Set Accuracy after, 15200 iteration =  61.72 %\n",
      "Training Set Cost after, 15200 iteration =  47.558\n",
      "Validation Set Accuracy after, 15200 iteration =  51.06 %\n",
      "\n",
      "Training Set Accuracy after, 15300 iteration =  53.91 %\n",
      "Training Set Cost after, 15300 iteration =  47.758\n",
      "Validation Set Accuracy after, 15300 iteration =  52.66 %\n",
      "\n",
      "Training Set Accuracy after, 15400 iteration =  61.72 %\n",
      "Training Set Cost after, 15400 iteration =  47.536\n",
      "Validation Set Accuracy after, 15400 iteration =  51.4 %\n",
      "\n",
      "Training Set Accuracy after, 15500 iteration =  62.5 %\n",
      "Training Set Cost after, 15500 iteration =  47.528\n",
      "Validation Set Accuracy after, 15500 iteration =  51.68 %\n",
      "\n",
      "Training Set Accuracy after, 15600 iteration =  57.03 %\n",
      "Training Set Cost after, 15600 iteration =  47.571\n",
      "Validation Set Accuracy after, 15600 iteration =  53.52 %\n",
      "\n",
      "Training Set Accuracy after, 15700 iteration =  60.94 %\n",
      "Training Set Cost after, 15700 iteration =  47.493\n",
      "Validation Set Accuracy after, 15700 iteration =  52.6 %\n",
      "\n",
      "Training Set Accuracy after, 15800 iteration =  63.28 %\n",
      "Training Set Cost after, 15800 iteration =  47.625\n",
      "Validation Set Accuracy after, 15800 iteration =  52.6 %\n",
      "\n",
      "Training Set Accuracy after, 15900 iteration =  57.03 %\n",
      "Training Set Cost after, 15900 iteration =  47.496\n",
      "Validation Set Accuracy after, 15900 iteration =  53.06 %\n",
      "\n",
      "Training Set Accuracy after, 16000 iteration =  55.47 %\n",
      "Training Set Cost after, 16000 iteration =  47.467\n",
      "Validation Set Accuracy after, 16000 iteration =  53.04 %\n",
      "\n",
      "Training Set Accuracy after, 16100 iteration =  62.5 %\n",
      "Training Set Cost after, 16100 iteration =  47.452\n",
      "Validation Set Accuracy after, 16100 iteration =  51.5 %\n",
      "\n",
      "Training Set Accuracy after, 16200 iteration =  63.28 %\n",
      "Training Set Cost after, 16200 iteration =  47.555\n",
      "Validation Set Accuracy after, 16200 iteration =  50.92 %\n",
      "\n",
      "Training Set Accuracy after, 16300 iteration =  59.38 %\n",
      "Training Set Cost after, 16300 iteration =  47.599\n",
      "Validation Set Accuracy after, 16300 iteration =  50.84 %\n",
      "\n",
      "Training Set Accuracy after, 16400 iteration =  61.72 %\n",
      "Training Set Cost after, 16400 iteration =  47.396\n",
      "Validation Set Accuracy after, 16400 iteration =  52.04 %\n",
      "\n",
      "Training Set Accuracy after, 16500 iteration =  64.84 %\n",
      "Training Set Cost after, 16500 iteration =  47.362\n",
      "Validation Set Accuracy after, 16500 iteration =  52.36 %\n",
      "\n",
      "Training Set Accuracy after, 16600 iteration =  60.16 %\n",
      "Training Set Cost after, 16600 iteration =  47.364\n",
      "Validation Set Accuracy after, 16600 iteration =  52.98 %\n",
      "\n",
      "Training Set Accuracy after, 16700 iteration =  62.5 %\n",
      "Training Set Cost after, 16700 iteration =  47.263\n",
      "Validation Set Accuracy after, 16700 iteration =  51.96 %\n",
      "\n",
      "Training Set Accuracy after, 16800 iteration =  67.97 %\n",
      "Training Set Cost after, 16800 iteration =  47.232\n",
      "Validation Set Accuracy after, 16800 iteration =  53.9 %\n",
      "\n",
      "Training Set Accuracy after, 16900 iteration =  59.38 %\n",
      "Training Set Cost after, 16900 iteration =  47.374\n",
      "Validation Set Accuracy after, 16900 iteration =  52.62 %\n",
      "\n",
      "Training Set Accuracy after, 17000 iteration =  65.62 %\n",
      "Training Set Cost after, 17000 iteration =  47.283\n",
      "Validation Set Accuracy after, 17000 iteration =  50.74 %\n",
      "\n",
      "Training Set Accuracy after, 17100 iteration =  59.38 %\n",
      "Training Set Cost after, 17100 iteration =  47.32\n",
      "Validation Set Accuracy after, 17100 iteration =  53.4 %\n",
      "\n",
      "Training Set Accuracy after, 17200 iteration =  62.5 %\n",
      "Training Set Cost after, 17200 iteration =  47.288\n",
      "Validation Set Accuracy after, 17200 iteration =  51.66 %\n",
      "\n",
      "Training Set Accuracy after, 17300 iteration =  70.31 %\n",
      "Training Set Cost after, 17300 iteration =  47.094\n",
      "Validation Set Accuracy after, 17300 iteration =  52.88 %\n",
      "\n",
      "Training Set Accuracy after, 17400 iteration =  66.41 %\n",
      "Training Set Cost after, 17400 iteration =  47.274\n",
      "Validation Set Accuracy after, 17400 iteration =  50.82 %\n",
      "\n",
      "Training Set Accuracy after, 17500 iteration =  64.84 %\n",
      "Training Set Cost after, 17500 iteration =  47.231\n",
      "Validation Set Accuracy after, 17500 iteration =  53.2 %\n",
      "\n",
      "Training Set Accuracy after, 17600 iteration =  67.97 %\n",
      "Training Set Cost after, 17600 iteration =  47.099\n",
      "Validation Set Accuracy after, 17600 iteration =  52.66 %\n",
      "\n",
      "Training Set Accuracy after, 17700 iteration =  57.03 %\n",
      "Training Set Cost after, 17700 iteration =  47.256\n",
      "Validation Set Accuracy after, 17700 iteration =  52.86 %\n",
      "\n",
      "Training Set Accuracy after, 17800 iteration =  68.75 %\n",
      "Training Set Cost after, 17800 iteration =  47.157\n",
      "Validation Set Accuracy after, 17800 iteration =  51.06 %\n",
      "\n",
      "Training Set Accuracy after, 17900 iteration =  61.72 %\n",
      "Training Set Cost after, 17900 iteration =  47.114\n",
      "Validation Set Accuracy after, 17900 iteration =  53.62 %\n",
      "\n",
      "Training Set Accuracy after, 18000 iteration =  63.28 %\n",
      "Training Set Cost after, 18000 iteration =  47.263\n",
      "Validation Set Accuracy after, 18000 iteration =  52.98 %\n",
      "\n",
      "Training Set Accuracy after, 18100 iteration =  68.75 %\n",
      "Training Set Cost after, 18100 iteration =  47.0\n",
      "Validation Set Accuracy after, 18100 iteration =  53.46 %\n",
      "\n",
      "Training Set Accuracy after, 18200 iteration =  70.31 %\n",
      "Training Set Cost after, 18200 iteration =  46.999\n",
      "Validation Set Accuracy after, 18200 iteration =  53.28 %\n",
      "\n",
      "Training Set Accuracy after, 18300 iteration =  60.94 %\n",
      "Training Set Cost after, 18300 iteration =  47.245\n",
      "Validation Set Accuracy after, 18300 iteration =  53.36 %\n",
      "\n",
      "Training Set Accuracy after, 18400 iteration =  59.38 %\n",
      "Training Set Cost after, 18400 iteration =  47.263\n",
      "Validation Set Accuracy after, 18400 iteration =  49.94 %\n",
      "\n",
      "Training Set Accuracy after, 18500 iteration =  62.5 %\n",
      "Training Set Cost after, 18500 iteration =  47.279\n",
      "Validation Set Accuracy after, 18500 iteration =  53.08 %\n",
      "\n",
      "Training Set Accuracy after, 18600 iteration =  53.12 %\n",
      "Training Set Cost after, 18600 iteration =  47.3\n",
      "Validation Set Accuracy after, 18600 iteration =  51.5 %\n",
      "\n",
      "Training Set Accuracy after, 18700 iteration =  65.62 %\n",
      "Training Set Cost after, 18700 iteration =  47.068\n",
      "Validation Set Accuracy after, 18700 iteration =  52.46 %\n",
      "\n",
      "Training Set Accuracy after, 18800 iteration =  68.75 %\n",
      "Training Set Cost after, 18800 iteration =  47.028\n",
      "Validation Set Accuracy after, 18800 iteration =  53.84 %\n",
      "\n",
      "Training Set Accuracy after, 18900 iteration =  64.06 %\n",
      "Training Set Cost after, 18900 iteration =  47.135\n",
      "Validation Set Accuracy after, 18900 iteration =  52.64 %\n",
      "\n",
      "Training Set Accuracy after, 19000 iteration =  62.5 %\n",
      "Training Set Cost after, 19000 iteration =  47.178\n",
      "Validation Set Accuracy after, 19000 iteration =  50.82 %\n",
      "\n",
      "Training Set Accuracy after, 19100 iteration =  63.28 %\n",
      "Training Set Cost after, 19100 iteration =  47.06\n",
      "Validation Set Accuracy after, 19100 iteration =  52.72 %\n",
      "\n",
      "Training Set Accuracy after, 19200 iteration =  67.97 %\n",
      "Training Set Cost after, 19200 iteration =  47.036\n",
      "Validation Set Accuracy after, 19200 iteration =  52.16 %\n",
      "\n",
      "Training Set Accuracy after, 19300 iteration =  62.5 %\n",
      "Training Set Cost after, 19300 iteration =  47.077\n",
      "Validation Set Accuracy after, 19300 iteration =  52.42 %\n",
      "\n",
      "Training Set Accuracy after, 19400 iteration =  58.59 %\n",
      "Training Set Cost after, 19400 iteration =  47.124\n",
      "Validation Set Accuracy after, 19400 iteration =  52.74 %\n",
      "\n",
      "Training Set Accuracy after, 19500 iteration =  59.38 %\n",
      "Training Set Cost after, 19500 iteration =  47.146\n",
      "Validation Set Accuracy after, 19500 iteration =  53.28 %\n",
      "\n",
      "Training Set Accuracy after, 19600 iteration =  65.62 %\n",
      "Training Set Cost after, 19600 iteration =  46.982\n",
      "Validation Set Accuracy after, 19600 iteration =  52.22 %\n",
      "\n",
      "Training Set Accuracy after, 19700 iteration =  69.53 %\n",
      "Training Set Cost after, 19700 iteration =  47.007\n",
      "Validation Set Accuracy after, 19700 iteration =  52.34 %\n",
      "\n",
      "Training Set Accuracy after, 19800 iteration =  72.66 %\n",
      "Training Set Cost after, 19800 iteration =  46.928\n",
      "Validation Set Accuracy after, 19800 iteration =  53.4 %\n",
      "\n",
      "Training Set Accuracy after, 19900 iteration =  68.75 %\n",
      "Training Set Cost after, 19900 iteration =  46.985\n",
      "Validation Set Accuracy after, 19900 iteration =  53.4 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NN2 = NeuralNetwork(layer_dimensions, 'lrelu', 'SGD',drop_prob=0.2, reg_lambda=0.05)\n",
    "NN2.train(X_train, y_train, iters=20000, alpha=0.03, batch_size=128, print_every=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f68873e5b00>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f68873e5b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(NN.train_accuracy,label = \"Training Accuracy\")\n",
    "plt.plot(NN.val_accuracy, label = \"Validation Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 8 8 ... 5 5 4]\n"
     ]
    }
   ],
   "source": [
    "y_predicted2 = NN2.predict(X_test)\n",
    "save_predictions('ans2-uni', y_predicted2)\n",
    "print(y_predicted2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
